{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx1du__PqMWZ"
      },
      "source": [
        "The task in this notebook is to train a network which, given an image of a star, will calculate both the number of points on the star, as well as its width.\n",
        "\n",
        "Thus this will be a multi-task network, performing two completely different tasks simultaneously.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_ZOM0MBSTmVL"
      },
      "outputs": [],
      "source": [
        "#%% import stuff:\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKjDsEy8FjHr"
      },
      "source": [
        "The cell below assumes you have already downloaded the dataset from brightspace, and put it in your google drive folder. It demonstrates how to use google drive together with a colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w39eu-buTV55",
        "outputId": "a9a8a4d7-0844-47c6-92bb-05e36744d9c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "#temp=pickle.load(open('C:/Users/Jens/Documents/GitHub/DLsolutions/data/starData.p','rb')) # Windows\n",
        "temp=pickle.load(open('/home/jens/Documents/UNI/9. semester/Deep Learning/DLsolutions/data/starData.p','rb')) # Linux\n",
        "X=temp['X']\n",
        "y=temp['y']\n",
        "#reduce point labels from 3-9 to 0-6 for the net\n",
        "y[:,0] = y[:,0] - 3 \n",
        "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #Station√¶r\n",
        "device = \"cpu\" #laptop\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "mu0NWnqR9C-p",
        "outputId": "e6808207-eb4f-4a6b-f32c-a4aabe6a21cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 100, 100])\n",
            "tensor([0.0000, 5.4232])\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGgCAYAAADsNrNZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfn0lEQVR4nO3de3SV1b3u8ScXshIkWYFoVpKSQHDgDgIekZsBd60lu1SxhUK99GCLly1VgxLoEaEVuqtCkI6jFEQQdqU6CiJ0FFRasZygnFLDLRSUIgkWKtlCgm5JVgBZYNY8f3j6wuQSSbKSmcv3M8YaY/7e913vmpmQPJnvfLNWlDHGCACAZhbtugMAgPaJAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAONFkAbRgwQJ1795d8fHxGjx4sLZu3dpULwUAaIWimuK94F599VX96Ec/0qJFizR48GDNnTtXq1atUmlpqVJTU+t8bjgc1qFDh5SYmKioqKhIdw0A0MSMMaqpqVFGRoaio+uY55gmMGjQIJOfn+/VtbW1JiMjwxQWFn7lc8vLy40kHjx48ODRyh/l5eV1/ryPVYSdOnVKJSUlmjZtmrctOjpaeXl5Ki4uPu/4UCikUCjk1eb/T8g+2tFdSZ1YogKA1iZ4LKxu1/1DiYmJdR4X8QD69NNPVVtbq0AgYG0PBALau3fveccXFhbqF7/4xXnbkzpFKymRAAKA1uqrllGc/4SfNm2aqqurvUd5ebnrLgEAmkHEZ0CXX365YmJiVFlZaW2vrKxUWlraecf7fD75fL5IdwMA0MJFfAYUFxen/v37q6ioyNsWDodVVFSk3NzcSL8cAKCVivgMSJImT56scePGacCAARo0aJDmzp2r48eP65577mmKlwMAtEJNEkB33HGHPvnkE82YMUMVFRW69tprtW7duvNuTAAAtF9N8oeojREMBuX3+3W0rAd3wQFAKxSsCavzVftVXV2tpKSkix7HT3gAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAATtQrgAoLCzVw4EAlJiYqNTVVo0aNUmlpqXXMyZMnlZ+fr5SUFHXq1EljxoxRZWVlRDsNAGj96hVAGzduVH5+vjZv3qz169fr9OnT+ta3vqXjx497x0yaNElvvPGGVq1apY0bN+rQoUMaPXp0xDsOAGjdoowxpqFP/uSTT5SamqqNGzfq61//uqqrq3XFFVdo+fLl+v73vy9J2rt3r3r16qXi4mJdf/31550jFAopFAp5dTAYVGZmpo6W9VBSIlcIAaC1CdaE1fmq/aqurlZSUtJFj2vUT/jq6mpJUpcuXSRJJSUlOn36tPLy8rxjcnJylJWVpeLi4gueo7CwUH6/33tkZmY2pksAgFaiwQEUDodVUFCgoUOHqk+fPpKkiooKxcXFKTk52To2EAiooqLigueZNm2aqqurvUd5eXlDuwQAaEViG/rE/Px87d69W5s2bWpUB3w+n3w+X6POAQBofRo0A5owYYLWrl2rt99+W127dvW2p6Wl6dSpU6qqqrKOr6ysVFpaWqM6CgBoW+oVQMYYTZgwQatXr9aGDRuUnZ1t7e/fv786dOigoqIib1tpaakOHjyo3NzcyPQYANAm1OsSXH5+vpYvX67XXntNiYmJ3rqO3+9XQkKC/H6/7rvvPk2ePFldunRRUlKSHn74YeXm5l7wDjgAQPtVrwBauHChJOkb3/iGtX3p0qW6++67JUnPPvusoqOjNWbMGIVCIQ0fPlzPP/98RDoLAGg7GvV3QE0hGAzK7/fzd0AA0Eo1y98BAQDQUAQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOxLruANCSfXDqhNfecOJfrH35yeXN3R2gTWEGBABwggACADhBAAEAnGANCKjDCXPmW2TVo9+29j2w+AWrjoni9zmgPviOAQA4QQABAJwggAAATrAGBNQhRsZr+/6wzdp31Yb7rPrvw5Y2S5+AtoIZEADACQIIAOAEl+CAOnSICl90378UfGTV67b4rPrbHUNN0iegrWAGBABwggACADhBAAEAnGANCKhDXWtAtf/9mVX//Il7rfrbsxc2SZ+AtoIZEADACQIIAOAEAQQAcII1IKAOZ78Vz1dJfrnYqgfefrvX3nbdyoj1CWgrmAEBAJwggAAATnAJDqhDh6iGPzc1/3Ov/d7Gk9a+a+LiG35ioI1gBgQAcIIAAgA4QQABAJxgDQioQ2N+Q/vio3Kv/cNfTbb27Xr0+UacGWgbmAEBAJwggAAAThBAAAAnWAMC6hAX1Yg/BDpL2rPvWvXtY4ZZ9coeRRF5ndau1tgffxETxe/IbRn/ugAAJwggAIATBBAAwAnWgIA6NNVvaDUPXWHVh9ce89rpsZ2a6FXdOHD6mFWP3vnvVh39x85e+1/Hb7P2zU3f3nQdg3PMgAAAThBAAAAnuAQH1KFDE90GHH5vr1V/46VHvXbpfQub5DUjqez0cases+N+r52wxm/tS1m1y6pTT9hf+9+X9fPaXHJrX5gBAQCcIIAAAE40KoBmz56tqKgoFRQUeNtOnjyp/Px8paSkqFOnThozZowqKysb208AQBvT4DWgbdu26YUXXtA111xjbZ80aZL+8Ic/aNWqVfL7/ZowYYJGjx6tv/zlL43uLNDcOiimWV4n+xdnbj/+6a3299SswHvN0oe/nfrcqm/bfmZdJ2mNfWt459/ttOqMk3suet7wOXX5z4ZY9Yc38dEU7VWDZkDHjh3T2LFjtWTJEnXufOYe/urqav3617/WM888o29+85vq37+/li5dqnfffVebN2++4LlCoZCCwaD1AAC0fQ0KoPz8fI0YMUJ5eXnW9pKSEp0+fdranpOTo6ysLBUXF1/wXIWFhfL7/d4jMzOzIV0CALQy9Q6gFStWaMeOHSosLDxvX0VFheLi4pScnGxtDwQCqqiouOD5pk2bpurqau9RXl5+weMAAG1LvdaAysvLNXHiRK1fv17x8fER6YDP55PP54vIuYBIi4nQxzF8FfPFF1572yP9rX0nXrH/NqZjdNwln3dnKGTVd2w9s67TZU1Ha5//93+16szQ7oue99x1nbocu22wVW9/cO45R1z614O2pV4zoJKSEh05ckTXXXedYmNjFRsbq40bN2revHmKjY1VIBDQqVOnVFVVZT2vsrJSaWlpkew3AKCVq9cMaNiwYXr//fetbffcc49ycnL02GOPKTMzUx06dFBRUZHGjBkjSSotLdXBgweVm5sbuV4DAFq9egVQYmKi+vTpY2277LLLlJKS4m2/7777NHnyZHXp0kVJSUl6+OGHlZubq+uvvz5yvQaaSWwz3YZ9tug/25fC+rz2sFWvuOU5rz22+H5rX+oa+9J44uodVt399MVv6Tb16uXFRfXrbdWLfznXqjtGJ0ToldDaRfy94J599llFR0drzJgxCoVCGj58uJ5/nvv8AQC2RgfQO++8Y9Xx8fFasGCBFixY0NhTAwDaMN4LDgDgBB/HANQhpok+jqE+rpq806pnTDxzQ0+PL+x954rUus5XiQmkeu1Ry9+29vWOY80HF+b+uwsA0C4RQAAAJwggAIATrAEBl+rct+UxzbPCYs55O52WICrW/tERt/LM2Iz3H2ru7qCVYgYEAHCCAAIAOMElOKAOK2rOfOCizr0l29Q2b2dakNLF11r1gZ7/6aYjaNWYAQEAnCCAAABOEEAAACdYA0Kb96cTHaz6J+/f5rWj/2+yte9rb31q1bV7ys6uIt21VuPQlCFWfeDbvMM9Go8ZEADACQIIAOAEAQQAcII1ILQKW0OnrXrCnv9p1cc3XeG1M/9Ube0zJX+z6gztuejrtN9VnvN9PnKQ1y5+5Jlz9sYLaCxmQAAAJwggAIATBBAAwAnWgNBsyk4ft+oH9/3Aqg/9uavXzvw/J6x9Ue/usurOZp9d60zdXB9D3dZE98mx6mfnPue1O0Wz5oPIYwYEAHCCAAIAOMElONRbrQl77R8c+Ddr384/X2XVXYtOee24d+zLaLFfHLTqLNk1mlZMSher/tarm626vy+uObuDdogZEADACQIIAOAEAQQAcII1INRbzFkfTf1Q+tvWvn/PyrLqkyk+rx0XE2Of6IsvIt85XLLDL6ZadUHnDY56gvaKGRAAwAkCCADgBAEEAHCCNSA0yjcSwlb94U1L7QNuOtMsm2O/Fc8dO++z6pi1nb126ir7IxNqq+yPWEDjdVjd2d4w0E0/0H4xAwIAOEEAAQCciDLGtKg3Dw4Gg/L7/Tpa1kNJieRje/VprX257gdld1p15R8yrTrz1X947S8+PtRk/WrLyl4cYNUHvv2fjnqC1i5YE1bnq/arurpaSUlJFz2On/AAACcIIACAEwQQAMAJ1oDQJoTMaa99/8Fh1r5tb/ax6uxXj3jt2tIPm7ZjrUh0vP2pp/03n1mHeyr1/ebuDlox1oAAAC0aAQQAcIIAAgA4wRoQ2rXHj/S16lf/dINVX7myxmub7bubpU8tRfT/6OW1n3t9ibXvyg6dmrs7aEVYAwIAtGgEEADACS7BAXUY/eG/ee3jX//EYU/c+uSBXKveMWOho56gNeASHACgRSOAAABOEEAAACf4RFSgDv9Vk+y1O6v9rgFdsajYqq+6cZxVl934UnN2B20EMyAAgBMEEADACQIIAOAEa0BAHY5WX+a1OzvsR0tz5fj9Vv1McQ+vPbnL/nMPBy6IGRAAwAkCCADgBAEEAHCCNSCgDl8E45r9NWOS/VZ97dtHrfp3e/t57a5LO1j7Ovxpe9N17CzhmhqrfuveoV77B797z9qXHstHN+DCmAEBAJwggAAATnAJDqhDbHVMs7/m31/oZtV/DGy06lmBsy5x3Wg/95efXWnVL64cbtU9lpy5RfqLwxWN6OU5tr7vNYfPnWLteu9/PR+510GbwgwIAOAEAQQAcKLeAfTxxx/rrrvuUkpKihISEtS3b19t337mzhtjjGbMmKH09HQlJCQoLy9P+/bti2inAQCtX73WgI4ePaqhQ4fqpptu0ptvvqkrrrhC+/btU+fOZ96kZM6cOZo3b55eeuklZWdna/r06Ro+fLj27Nmj+Pj4iH8BQFOKq45qltf5dPyZj7wu/deGf9z1o13+btcP2OsvR+8/4bWH/fUea1/Hl5Kt+rLfbz1TGHPJfUh/5l2rvubrP7Dq9wa9csnnQttWrwB6+umnlZmZqaVLl3rbsrOzvbYxRnPnztXjjz+ukSNHSpJefvllBQIBrVmzRnfeeed55wyFQgqFQl4dDAbr/UUAAFqfel2Ce/311zVgwADddtttSk1NVb9+/bRkyRJv/4EDB1RRUaG8vDxvm9/v1+DBg1VcXHyhU6qwsFB+v997ZGZmNvBLAQC0JvUKoP3792vhwoXq2bOn3nrrLT344IN65JFH9NJLX34aYkXFl7d1BgIB63mBQMDbd65p06apurrae5SXlzfk6wAAtDL1ugQXDoc1YMAAzZo1S5LUr18/7d69W4sWLdK4ceO+4tkX5vP55PP5GvRcoKnFNdEV4ZhePa36tz/932dVHZvmRSV1jjlz7h0DXrV3DrDLZbNSvPZ/rL7d2nfV4sNW/cX+f1z0NbveY//y+et306z6Pn8E/x4JrUq9ZkDp6em6+uqrrW29evXSwYMHJUlpaV/+x6qsrLSOqays9PYBACDVM4CGDh2q0tJSa1tZWZm6dfvyL7ezs7OVlpamoqIib38wGNSWLVuUm5srAAD+qV6X4CZNmqQhQ4Zo1qxZuv3227V161YtXrxYixcvliRFRUWpoKBATz31lHr27Ondhp2RkaFRo0Y1Rf+BJuWrCkfkPFGx9rda5kv/ZdW94prusltDjU387zPtH9m3hod+eNqqb/lgjNc+9vLXrH2dl2+z6hXjb7bq0csXnDk2puWNA5pOvQJo4MCBWr16taZNm6YnnnhC2dnZmjt3rsaOHesdM2XKFB0/flzjx49XVVWVbrjhBq1bt46/AQIAWOr9ZqS33nqrbr311ovuj4qK0hNPPKEnnniiUR0DALRtvBccAMAJPo4BqEP80dqInGffHPse53VdF0XkvK74ouxPYi26+vUzxWz72KKf2x9pcf+b/a36unUTvfaBEUuE9oMZEADACQIIAOAEAQQAcII1IKAOcUdPNfi5J28d5LX33DH/nL0d1F4MS7DX0faPfsFRT9DSMAMCADhBAAEAnOASHFCH2E+Pee2vuiE7JpBq1T959rde+9zblgEwAwIAOEIAAQCcIIAAAE6wBgTU5ZPPLvnQz5YmWfV3LzsR6d4AbQozIACAEwQQAMAJAggA4ARrQMBZQsb+qOnao0cveuzhnwyx6veufb5J+gS0VcyAAABOEEAAACcIIACAE6wBAWcpPX3xd3yLGtDHqv84cc45R3Rqgh4BbRczIACAEwQQAMAJLsEBZ9kTSrfq6Ph4r339r3dY+7rGcskNaAxmQAAAJwggAIATBBAAwAnWgICzlJ6014D2zu/rtd+8Yklzdwdo05gBAQCcIIAAAE4QQAAAJ1gDAs7yfX+JVT9+y+6zKn5fAyKJ7ygAgBMEEADACS7BAWfpHZfgugtAu8EMCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcqFcA1dbWavr06crOzlZCQoKuvPJKPfnkkzLGeMcYYzRjxgylp6crISFBeXl52rdvX8Q7DgBo3eoVQE8//bQWLlyo5557Th988IGefvppzZkzR/Pnz/eOmTNnjubNm6dFixZpy5YtuuyyyzR8+HCdPHky4p0HALResfU5+N1339XIkSM1YsQISVL37t31yiuvaOvWrZK+nP3MnTtXjz/+uEaOHClJevnllxUIBLRmzRrdeeed550zFAopFAp5dTAYbPAXAwBoPeo1AxoyZIiKiopUVlYmSdq1a5c2bdqkm2++WZJ04MABVVRUKC8vz3uO3+/X4MGDVVxcfMFzFhYWyu/3e4/MzMyGfi0AgFakXjOgqVOnKhgMKicnRzExMaqtrdXMmTM1duxYSVJFRYUkKRAIWM8LBALevnNNmzZNkydP9upgMEgIAUA7UK8AWrlypZYtW6bly5erd+/e2rlzpwoKCpSRkaFx48Y1qAM+n08+n69BzwUAtF71CqBHH31UU6dO9dZy+vbtq48++kiFhYUaN26c0tLSJEmVlZVKT0/3nldZWalrr702cr0GALR69VoDOnHihKKj7afExMQoHA5LkrKzs5WWlqaioiJvfzAY1JYtW5SbmxuB7gIA2op6zYC+853vaObMmcrKylLv3r3117/+Vc8884zuvfdeSVJUVJQKCgr01FNPqWfPnsrOztb06dOVkZGhUaNGNUX/AQCtVL0CaP78+Zo+fboeeughHTlyRBkZGfrxj3+sGTNmeMdMmTJFx48f1/jx41VVVaUbbrhB69atU3x8fMQ7DwBovaLM2W9j0AIEg0H5/X4dLeuhpETeKQgAWptgTVidr9qv6upqJSUlXfQ4fsIDAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcCLWdQfOZYyRJAWPhR33BADQEP/8+f3Pn+cX0+ICqKamRpLU7bp/uO0IAKBRampq5Pf7L7o/ynxVRDWzcDisQ4cOyRijrKwslZeXKykpyXW3WqxgMKjMzEzG6SswTpeGcbo0jFPdjDGqqalRRkaGoqMvvtLT4mZA0dHR6tq1q4LBoCQpKSmJf+BLwDhdGsbp0jBOl4Zxuri6Zj7/xE0IAAAnCCAAgBMtNoB8Pp9+/vOfy+fzue5Ki8Y4XRrG6dIwTpeGcYqMFncTAgCgfWixMyAAQNtGAAEAnCCAAABOEEAAACcIIACAEy02gBYsWKDu3bsrPj5egwcP1tatW113yZnCwkINHDhQiYmJSk1N1ahRo1RaWmodc/LkSeXn5yslJUWdOnXSmDFjVFlZ6ajHLcPs2bMVFRWlgoICbxvj9KWPP/5Yd911l1JSUpSQkKC+fftq+/bt3n5jjGbMmKH09HQlJCQoLy9P+/btc9jj5ldbW6vp06crOztbCQkJuvLKK/Xkk09ab7DJODWSaYFWrFhh4uLizIsvvmj+9re/mfvvv98kJyebyspK111zYvjw4Wbp0qVm9+7dZufOneaWW24xWVlZ5tixY94xDzzwgMnMzDRFRUVm+/bt5vrrrzdDhgxx2Gu3tm7darp3726uueYaM3HiRG8742TMZ599Zrp162buvvtus2XLFrN//37z1ltvmQ8//NA7Zvbs2cbv95s1a9aYXbt2me9+97smOzvbfP755w573rxmzpxpUlJSzNq1a82BAwfMqlWrTKdOncyvfvUr7xjGqXFaZAANGjTI5Ofne3Vtba3JyMgwhYWFDnvVchw5csRIMhs3bjTGGFNVVWU6dOhgVq1a5R3zwQcfGEmmuLjYVTedqampMT179jTr1683N954oxdAjNOXHnvsMXPDDTdcdH84HDZpaWnml7/8pbetqqrK+Hw+88orrzRHF1uEESNGmHvvvdfaNnr0aDN27FhjDOMUCS3uEtypU6dUUlKivLw8b1t0dLTy8vJUXFzssGctR3V1tSSpS5cukqSSkhKdPn3aGrOcnBxlZWW1yzHLz8/XiBEjrPGQGKd/ev311zVgwADddtttSk1NVb9+/bRkyRJv/4EDB1RRUWGNk9/v1+DBg9vVOA0ZMkRFRUUqKyuTJO3atUubNm3SzTffLIlxioQW927Yn376qWpraxUIBKztgUBAe/fuddSrliMcDqugoEBDhw5Vnz59JEkVFRWKi4tTcnKydWwgEFBFRYWDXrqzYsUK7dixQ9u2bTtvH+P0pf3792vhwoWaPHmyfvrTn2rbtm165JFHFBcXp3HjxnljcaHvwfY0TlOnTlUwGFROTo5iYmJUW1urmTNnauzYsZLEOEVAiwsg1C0/P1+7d+/Wpk2bXHelxSkvL9fEiRO1fv16xcfHu+5OixUOhzVgwADNmjVLktSvXz/t3r1bixYt0rhx4xz3ruVYuXKlli1bpuXLl6t3797auXOnCgoKlJGRwThFSIu7BHf55ZcrJibmvDuTKisrlZaW5qhXLcOECRO0du1avf322+ratau3PS0tTadOnVJVVZV1fHsbs5KSEh05ckTXXXedYmNjFRsbq40bN2revHmKjY1VIBBgnCSlp6fr6quvtrb16tVLBw8elCRvLNr79+Cjjz6qqVOn6s4771Tfvn31wx/+UJMmTVJhYaEkxikSWlwAxcXFqX///ioqKvK2hcNhFRUVKTc312HP3DHGaMKECVq9erU2bNig7Oxsa3///v3VoUMHa8xKS0t18ODBdjVmw4YN0/vvv6+dO3d6jwEDBmjs2LFem3GShg4det5t/GVlZerWrZskKTs7W2lpadY4BYNBbdmypV2N04kTJ877NM+YmBiFw2FJjFNEuL4L4kJWrFhhfD6f+c1vfmP27Nljxo8fb5KTk01FRYXrrjnx4IMPGr/fb9555x1z+PBh73HixAnvmAceeMBkZWWZDRs2mO3bt5vc3FyTm5vrsNctw9l3wRnDOBnz5S3qsbGxZubMmWbfvn1m2bJlpmPHjua3v/2td8zs2bNNcnKyee2118x7771nRo4c2e5uLx43bpz52te+5t2G/fvf/95cfvnlZsqUKd4xjFPjtMgAMsaY+fPnm6ysLBMXF2cGDRpkNm/e7LpLzki64GPp0qXeMZ9//rl56KGHTOfOnU3Hjh3N9773PXP48GF3nW4hzg0gxulLb7zxhunTp4/x+XwmJyfHLF682NofDofN9OnTTSAQMD6fzwwbNsyUlpY66q0bwWDQTJw40WRlZZn4+HjTo0cP87Of/cyEQiHvGMapcfg8IACAEy1uDQgA0D4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIAT/w974gKrDKtgHQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Let's plot an example\n",
        "\n",
        "idx=1250\n",
        "plt.imshow(np.squeeze(X[125,:,:,:],axis=0))\n",
        "img = X[idx,:,:,:]\n",
        "\n",
        "print(img.shape)\n",
        "print(y[idx,:]) #first column is number of points, second is size of the star"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "14iffVhhTkWY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "num_classes = torch.unique(y[:,0]).shape[0]\n",
        "print(num_classes)\n",
        "\n",
        "batch_size = 4\n",
        "#%% make datasets & loaders\n",
        "dataset = TensorDataset(X, y)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "indices = list(range(len(dataset)))\n",
        "#split in val and train\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size = 0.5, random_state = 42)\n",
        "\n",
        "#make datasets (TensorDataset will do)\n",
        "#Create subsets of the data using the split indices\n",
        "train_data = TensorDataset(x_train, y_train)\n",
        "valid_data = TensorDataset(x_val, y_val)\n",
        "test_data = TensorDataset(x_test, y_test)\n",
        "\n",
        "\n",
        "#make dataloaders\n",
        "train_dl = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "valid_dl = DataLoader(valid_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_dl = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6HtnbXn0NXyj"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.0105,  0.0126,  0.0142, -0.0634,  0.0815, -0.0111,  0.0489]],\n",
              "        grad_fn=<AddmmBackward0>),\n",
              " tensor([[0.0399]], grad_fn=<AddmmBackward0>))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#%% make network\n",
        "class MTLNet(nn.Module):\n",
        " def __init__(self):\n",
        "     super(MTLNet, self).__init__()\n",
        "     self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding='same')\n",
        "     self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding='same')\n",
        "     \n",
        "     self.flatten = nn.Flatten()\n",
        "     self.fc1 = nn.Linear(64*100*100, 512)\n",
        "     self.fc2 = nn.Linear(512, 128)\n",
        "     self.relU = nn.ReLU()\n",
        "\n",
        "     self.fc_points = nn.Linear(128, num_classes)\n",
        "     self.fc_width = nn.Linear(128, 1)\n",
        "\n",
        "     \n",
        "     \n",
        " def forward(self,x):\n",
        "     x = self.conv1(x)\n",
        "     x = self.relU(x)\n",
        "     x = self.conv2(x)\n",
        "     x = self.relU(x)\n",
        "\n",
        "     x = self.flatten(x)\n",
        "     \n",
        "     x = self.fc1(x)\n",
        "     x = self.relU(x)\n",
        "     x = self.fc2(x)\n",
        "\n",
        "     points_out = self.fc_points(x)\n",
        "     width_out = self.fc_width(x)\n",
        "     \n",
        "     return points_out, width_out\n",
        "#something simple like cnn-cnn-fc-relu-fc will do\n",
        "\n",
        "\n",
        "\n",
        "#testing:\n",
        "testData=torch.rand((1,1,100,100)).to(device)\n",
        "testNet=MTLNet()\n",
        "testNet.to(device)\n",
        "testNet.forward(testData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kCUFfJsFN7op"
      },
      "outputs": [],
      "source": [
        "#%% define loss'es\n",
        "loss_classi=nn.CrossEntropyLoss()\n",
        "loss_regress=nn.MSELoss()\n",
        "#some combination of losses\n",
        "loss_fn = lambda x,z,y: (loss_classi(x,(y[:,0]).long()) + loss_regress(z,y[:,1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gOCTOuj3FR0X"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jens/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20] Train Loss: nan, Validation Loss: nan\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/jens/Documents/UNI/9. semester/Deep Learning/DLsolutions/w6_MTL_star_student_edition.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jens/Documents/UNI/9.%20semester/Deep%20Learning/DLsolutions/w6_MTL_star_student_edition.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(points_out, width_out, ybatch)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jens/Documents/UNI/9.%20semester/Deep%20Learning/DLsolutions/w6_MTL_star_student_edition.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jens/Documents/UNI/9.%20semester/Deep%20Learning/DLsolutions/w6_MTL_star_student_edition.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jens/Documents/UNI/9.%20semester/Deep%20Learning/DLsolutions/w6_MTL_star_student_edition.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jens/Documents/UNI/9.%20semester/Deep%20Learning/DLsolutions/w6_MTL_star_student_edition.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m totLoss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/sgd.py:76\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     72\u001b[0m momentum_buffer_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     74\u001b[0m has_sparse_grad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(group, params_with_grad, d_p_list, momentum_buffer_list)\n\u001b[0;32m---> 76\u001b[0m sgd(params_with_grad,\n\u001b[1;32m     77\u001b[0m     d_p_list,\n\u001b[1;32m     78\u001b[0m     momentum_buffer_list,\n\u001b[1;32m     79\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     80\u001b[0m     momentum\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmomentum\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     81\u001b[0m     lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     82\u001b[0m     dampening\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdampening\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     83\u001b[0m     nesterov\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mnesterov\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     84\u001b[0m     maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     85\u001b[0m     has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[1;32m     86\u001b[0m     foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     88\u001b[0m \u001b[39m# update momentum_buffers in state\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39mfor\u001b[39;00m p, momentum_buffer \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(params_with_grad, momentum_buffer_list):\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/sgd.py:222\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_sgd\n\u001b[0;32m--> 222\u001b[0m func(params,\n\u001b[1;32m    223\u001b[0m      d_p_list,\n\u001b[1;32m    224\u001b[0m      momentum_buffer_list,\n\u001b[1;32m    225\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    226\u001b[0m      momentum\u001b[39m=\u001b[39;49mmomentum,\n\u001b[1;32m    227\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    228\u001b[0m      dampening\u001b[39m=\u001b[39;49mdampening,\n\u001b[1;32m    229\u001b[0m      nesterov\u001b[39m=\u001b[39;49mnesterov,\n\u001b[1;32m    230\u001b[0m      has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[1;32m    231\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/sgd.py:258\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    256\u001b[0m     momentum_buffer_list[i] \u001b[39m=\u001b[39m buf\n\u001b[1;32m    257\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 258\u001b[0m     buf\u001b[39m.\u001b[39;49mmul_(momentum)\u001b[39m.\u001b[39;49madd_(d_p, alpha\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m dampening)\n\u001b[1;32m    260\u001b[0m \u001b[39mif\u001b[39;00m nesterov:\n\u001b[1;32m    261\u001b[0m     d_p \u001b[39m=\u001b[39m d_p\u001b[39m.\u001b[39madd(buf, alpha\u001b[39m=\u001b[39mmomentum)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#%% train & validate\n",
        "\n",
        "nEpoch=20\n",
        "net=MTLNet()\n",
        "net.to(device)\n",
        "optimizer=torch.optim.SGD(net.parameters(),lr=0.01,momentum=0.9)\n",
        "\n",
        "running_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "for iEpoch in range(nEpoch):\n",
        "    net.train()\n",
        "    totLoss=0\n",
        "    num_batches=0\n",
        "    for xbatch,ybatch in train_dl:\n",
        "        xbatch=xbatch.to(device)\n",
        "        ybatch=ybatch.to(device)\n",
        "        \n",
        "        points_out, width_out = net(xbatch)\n",
        "        loss = loss_fn(points_out, width_out, ybatch).to(device)\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        totLoss += loss.item()\n",
        "        num_batches += 1\n",
        "        \n",
        "    avg_loss = totLoss / num_batches\n",
        "    running_loss.append(avg_loss)\n",
        "        #the usual. pass the output of your network to the custom loss function you made above\n",
        "        #use it to update the weights\n",
        "\n",
        "\n",
        "    net.eval()  # Set model to evaluation mode\n",
        "    totValLoss = 0\n",
        "    num_val_batches = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation during validation\n",
        "        for xbatch, ybatch in valid_dl:\n",
        "            xbatch = xbatch\n",
        "            ybatch = ybatch\n",
        "            \n",
        "            points_out, width_out = net(xbatch)\n",
        "            loss = loss_fn(points_out, width_out, ybatch)\n",
        "            \n",
        "            totValLoss += loss.item()\n",
        "            num_val_batches += 1\n",
        "\n",
        "    avg_val_loss = totValLoss / num_val_batches\n",
        "    validation_loss.append(avg_val_loss)\n",
        "    print(f\"Epoch [{iEpoch+1}/{nEpoch}] Train Loss: {avg_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5l1QdAgPB6z"
      },
      "outputs": [],
      "source": [
        "#evaluate\n",
        "\n",
        "#try plotting predictions vs. targets for both training data and validation data in a scatterplot, and see how much variation you've captured"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
