{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx1du__PqMWZ"
      },
      "source": [
        "The task in this notebook is to train a network which, given an image of a star, will calculate both the number of points on the star, as well as its width.\n",
        "\n",
        "Thus this will be a multi-task network, performing two completely different tasks simultaneously.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_ZOM0MBSTmVL"
      },
      "outputs": [],
      "source": [
        "#%% import stuff:\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKjDsEy8FjHr"
      },
      "source": [
        "The cell below assumes you have already downloaded the dataset from brightspace, and put it in your google drive folder. It demonstrates how to use google drive together with a colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w39eu-buTV55",
        "outputId": "a9a8a4d7-0844-47c6-92bb-05e36744d9c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "temp=pickle.load(open('C:/Users/Jens/Documents/GitHub/DLsolutions/data/starData.p','rb')) # Windows\n",
        "#temp=pickle.load(open('/home/jens/Documents/UNI/9. semester/Deep Learning/DLsolutions/data/starData.p','rb')) # Linux\n",
        "X=temp['X']\n",
        "y=temp['y']\n",
        "#reduce point labels from 3-9 to 0-6 for the net\n",
        "y[:,0] = y[:,0] - 3 \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #Station√¶r\n",
        "#device = \"cpu\" #laptop\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "mu0NWnqR9C-p",
        "outputId": "e6808207-eb4f-4a6b-f32c-a4aabe6a21cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 100, 100])\n",
            "tensor([2.0000, 0.8301])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Let's plot an example\n",
        "\n",
        "idx=150\n",
        "plt.imshow(np.squeeze(X[125,:,:,:],axis=0))\n",
        "img = X[idx,:,:,:]\n",
        "# Data normalization for star size:\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "y[:,1:2] = torch.tensor(scaler.fit_transform(y[:,1:2].numpy()))\n",
        "print(img.shape)\n",
        "print(y[idx,:]) #first column is number of points, second is size of the star"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "14iffVhhTkWY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "num_classes = torch.unique(y[:,0]).shape[0]\n",
        "print(num_classes)\n",
        "\n",
        "batch_size = 64\n",
        "#%% make datasets & loaders\n",
        "dataset = TensorDataset(X, y)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "indices = list(range(len(dataset)))\n",
        "#split in val and train\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size = 0.5, random_state = 42)\n",
        "\n",
        "#make datasets (TensorDataset will do)\n",
        "#Create subsets of the data using the split indices\n",
        "train_data = TensorDataset(x_train, y_train)\n",
        "valid_data = TensorDataset(x_val, y_val)\n",
        "test_data = TensorDataset(x_test, y_test)\n",
        "\n",
        "\n",
        "#make dataloaders\n",
        "train_dl = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "valid_dl = DataLoader(valid_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_dl = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6HtnbXn0NXyj"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.0844,  0.0435,  0.0536, -0.0532,  0.0548, -0.0420,  0.0486]],\n",
              "        device='cuda:0', grad_fn=<AddmmBackward0>),\n",
              " tensor([[-0.0351]], device='cuda:0', grad_fn=<AddmmBackward0>))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#%% make network\n",
        "class MTLNet(nn.Module):\n",
        " def __init__(self):\n",
        "     super(MTLNet, self).__init__()\n",
        "     self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding='same')\n",
        "     self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding='same')\n",
        "     self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding='same')\n",
        "     self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "     \n",
        "     self.flatten = nn.Flatten()\n",
        "     self.fc1 = nn.Linear(128*25*25, 512)\n",
        "     self.fc2 = nn.Linear(512, 128)\n",
        "     self.relU = nn.ReLU()\n",
        "\n",
        "     self.fc_points = nn.Linear(128, num_classes)\n",
        "     self.fc_width = nn.Linear(128, 1)\n",
        "\n",
        "     \n",
        "     \n",
        " def forward(self,x):\n",
        "     x = self.conv1(x)\n",
        "     x = self.relU(x)\n",
        "     x = self.pool1(x)\n",
        "     x = self.conv2(x)\n",
        "     x = self.relU(x)\n",
        "     x = self.pool1(x)\n",
        "     x = self.conv3(x)\n",
        "     x = self.relU(x)\n",
        "\n",
        "     x = self.flatten(x)\n",
        "     \n",
        "     x = self.fc1(x)\n",
        "     x = self.relU(x)\n",
        "     x = self.fc2(x)\n",
        "\n",
        "     points_out = self.fc_points(x)\n",
        "     width_out = self.fc_width(x)\n",
        "     \n",
        "     return points_out, width_out\n",
        "#something simple like cnn-cnn-fc-relu-fc will do\n",
        "\n",
        "\n",
        "\n",
        "#testing:\n",
        "testData=torch.rand((1,1,100,100)).to(device)\n",
        "testNet=MTLNet()\n",
        "testNet.to(device)\n",
        "testNet.forward(testData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kCUFfJsFN7op"
      },
      "outputs": [],
      "source": [
        "#%% define loss'es\n",
        "loss_classi=nn.CrossEntropyLoss()\n",
        "loss_regress=nn.MSELoss()\n",
        "#some combination of losses\n",
        "alpha = 0.5\n",
        "loss_fn = lambda x,z,y: (alpha * loss_classi(x,(y[:,0]).long()) + ((1-alpha) * loss_regress(z,y[:,1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gOCTOuj3FR0X"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Jens\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "c:\\Users\\Jens\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "c:\\Users\\Jens\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([44])) that is different to the input size (torch.Size([44, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20] Train Loss: 49190.6328, Validation Loss: 1.0704\n",
            "Epoch [2/20] Train Loss: 1.0225, Validation Loss: 1.0047\n",
            "Epoch [3/20] Train Loss: 0.9946, Validation Loss: 0.9818\n",
            "Epoch [4/20] Train Loss: 0.9517, Validation Loss: 0.9131\n",
            "Epoch [5/20] Train Loss: 0.8089, Validation Loss: 0.6791\n",
            "Epoch [6/20] Train Loss: 0.5953, Validation Loss: 0.5770\n",
            "Epoch [7/20] Train Loss: 0.4546, Validation Loss: 0.3728\n",
            "Epoch [8/20] Train Loss: 0.2923, Validation Loss: 0.3613\n",
            "Epoch [9/20] Train Loss: 0.2413, Validation Loss: 0.2102\n",
            "Epoch [10/20] Train Loss: 0.2266, Validation Loss: 0.2569\n",
            "Epoch [11/20] Train Loss: 0.1973, Validation Loss: 0.1518\n",
            "Epoch [12/20] Train Loss: 0.1415, Validation Loss: 0.1135\n",
            "Epoch [13/20] Train Loss: 0.1106, Validation Loss: 0.2364\n",
            "Epoch [14/20] Train Loss: 0.1329, Validation Loss: 0.1575\n",
            "Epoch [15/20] Train Loss: 0.1173, Validation Loss: 0.0907\n",
            "Epoch [16/20] Train Loss: 0.0810, Validation Loss: 0.0774\n",
            "Epoch [17/20] Train Loss: 0.0666, Validation Loss: 0.0708\n",
            "Epoch [18/20] Train Loss: 0.0637, Validation Loss: 0.0706\n",
            "Epoch [19/20] Train Loss: 0.0657, Validation Loss: 0.0648\n",
            "Epoch [20/20] Train Loss: 0.0690, Validation Loss: 0.0712\n"
          ]
        }
      ],
      "source": [
        "#%% train & validate\n",
        "\n",
        "nEpoch=20\n",
        "net=MTLNet()\n",
        "net.to(device)\n",
        "optimizer=torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "running_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "for iEpoch in range(nEpoch):\n",
        "    net.train()\n",
        "    totLoss=0\n",
        "    num_batches=0\n",
        "    for xbatch,ybatch in train_dl:\n",
        "        optimizer.zero_grad()\n",
        "        xbatch=xbatch.to(device)\n",
        "        ybatch=ybatch.to(device)\n",
        "        \n",
        "        points_out, width_out = net(xbatch)\n",
        "        #print('Points out: ', points_out, '\\nWidht out: ', width_out)\n",
        "        \n",
        "        loss = loss_fn(points_out, width_out, ybatch).to(device)\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        totLoss += loss\n",
        "        num_batches += 1\n",
        "        \n",
        "    avg_loss = totLoss / num_batches\n",
        "    running_loss.append(avg_loss)\n",
        "        #the usual. pass the output of your network to the custom loss function you made above\n",
        "        #use it to update the weights\n",
        "\n",
        "\n",
        "    net.eval()  # Set model to evaluation mode\n",
        "    totValLoss = 0\n",
        "    num_val_batches = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation during validation\n",
        "        for xbatch, ybatch in valid_dl:\n",
        "            xbatch = xbatch.to(device)\n",
        "            ybatch = ybatch.to(device)\n",
        "            \n",
        "            points_out, width_out = net(xbatch)\n",
        "            loss = loss_fn(points_out, width_out, ybatch).to(device)\n",
        "            \n",
        "            totValLoss += loss\n",
        "            num_val_batches += 1\n",
        "\n",
        "    avg_val_loss = totValLoss / num_val_batches\n",
        "    validation_loss.append(avg_val_loss)\n",
        "    print(f\"Epoch [{iEpoch+1}/{nEpoch}] Train Loss: {avg_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "u5l1QdAgPB6z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test data: 99.00%\n",
            "Deviation on test regression data: 0.11\n"
          ]
        }
      ],
      "source": [
        "#evaluate\n",
        "net.eval()\n",
        "\n",
        "#Correct predictions\n",
        "correct = 0\n",
        "total = 0\n",
        "rmse_val = 0\n",
        "# We dont need to compute gradients for our test, so we can use torch.no_grad()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_dl:\n",
        "        labels = labels.to(device)\n",
        "        points, width = net(inputs.to(device))\n",
        "        predicted = torch.max(points, 1)[1]\n",
        "        true = labels[:,0].long()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == true).sum().item()\n",
        "        rmse_val = loss_regress(width, labels[:,1].to(device))\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy on test data: {accuracy:.2f}%')\n",
        "print(f'Deviation on test regression data: {rmse_val:.2f}')\n",
        "#try plotting predictions vs. targets for both training data and validation data in a scatterplot, and see how much variation you've captured\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
