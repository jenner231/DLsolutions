{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSGGbdAR2QUR"
      },
      "source": [
        "## Credit\n",
        "The exercise is based on material from the course _Deep Learning for Visual Recognition_.\n",
        "https://kursuskatalog.au.dk/da/course/93556/Deep-Learning-for-Visual-Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mihd9hpHKVh"
      },
      "source": [
        "# Lab 4: Training neural networks\n",
        "In this lab we will explore different tools that will help you to train your own neural networks.\n",
        "\n",
        "We will be using fully connected networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tGBcfgIumcH"
      },
      "source": [
        "## 1. Download the CIFAR 10 dataset\n",
        "We will be using the CIFAR 10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "9e8fe30affad41a2b43bf4e2b55e63cc",
            "1abd5c7a5fb3464eb1debec6dcf5f58d",
            "5cf168e569e04dccbfb3bd735c6e95af",
            "07bf959eedb4418e8e75eb96ca0adcee",
            "0e9a6800a5f84b469fed68ab1e95c666",
            "56812773f2c3494eb909cdb58617a291",
            "ada66bc9efb4401e8d329e126dd84e21",
            "bed645e0dfd14175b2aadfddd9519417"
          ]
        },
        "id": "u_awI9jy3V9P",
        "outputId": "57cd890d-224b-4c34-f89f-c6ffb23d4ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Batch size\n",
        "bs = 256\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=bs,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iorLYSEz8Xbs"
      },
      "source": [
        "Display some stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "U50pDb-_5uKq",
        "outputId": "15aa6f58-518c-49e1-beb3-785245576151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train 50176\n",
            "num_test 10240\n",
            "images.shape torch.Size([256, 3, 32, 32])\n",
            "images.min() tensor(0.)\n",
            "images.max() tensor(1.)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  cat   dog truck   car\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Function to show an image\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Number of samples\n",
        "num_train = bs * len(trainloader)\n",
        "num_test = bs * len(testloader)\n",
        "print('num_train',num_train)\n",
        "print('num_test',num_test)\n",
        "\n",
        "# Get a batch of some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print('images.shape',images.shape)\n",
        "print('images.min()',images.min())\n",
        "print('images.max()',images.max())\n",
        "\n",
        "# show 4 images\n",
        "imshow(torchvision.utils.make_grid(images[0:4]))\n",
        "\n",
        "# print 4 labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PEUHshm8jNO"
      },
      "source": [
        "### Questions\n",
        "1. What is the batch size?\n",
        "2. What is the size of the images?\n",
        "3. What is the range of the pixel intensities?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "MVywxfqe2QUj"
      },
      "source": [
        "## Setting up device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wnEKbby2QUo",
        "outputId": "96438588-672f-4c84-b435-39d561c336ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device:',device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AdROOxx9ldc"
      },
      "source": [
        "## 2. Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNeIvBYdlrYC"
      },
      "source": [
        "In the transformer the input is scaled to range -1 to 1.\n",
        "The normalization is `(input[channel] - mean[channel]) / std[channel]`, where parameters (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) imply that the mean and standard deviation is set to 0.5 for all channels. See documentation [here](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Normalize). When reading the images from disk, the intensities are in the range 0 to 1. After normalization - and with these parameters - the output intensities will be in the range -1 to 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "ZHD3jAAK3lW0",
        "outputId": "c97ec3c1-585d-4233-d27f-0aec86e46641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "images.min() tensor(-1.)\n",
            "images.max() tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]) # Your code goes here\n",
        "\n",
        "# Re-initialize trainloader and testloader\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=False, num_workers=2)\n",
        "\n",
        "# Verify that intensities are in range -1 to 1\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print('images.min()',images.min())\n",
        "print('images.max()',images.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0n4oZ2y2MuE"
      },
      "source": [
        "### Questions\n",
        "Below you are going to initialize and normalize the network weights based. To prepare for this task, answer the following questions using appropriate PyTorch functions (use Google to figure out which):\n",
        "1. What is the mean and standard deviation (std) of tensor `x` below?\n",
        "2. What is the mean and std `y`?\n",
        "3. What is the mean and std `z`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0IHPLaP2OHx",
        "tags": []
      },
      "outputs": [],
      "source": [
        "x = torch.randn(512, 512)\n",
        "y = x * 10 + 2\n",
        "z = (y-2) / 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y945T69aHKVy"
      },
      "source": [
        "## 3. Base model\n",
        "We'll first create a base model that we can use for our initial experiments. The base model is a fully connected neural network. By default it has\n",
        "\n",
        "- `L = 10` layers\n",
        "- `N = 16` units in each hidden layer.\n",
        "\n",
        "When initializing the model you can specify\n",
        "\n",
        "- a `normalizer` function, which is applied when initializing the weight matrix `W` of each layer. The input to the normalizer functions is `W` and the output is some normalized version of `W`, like Xavier or Kaiming.\n",
        "\n",
        "- an `activation_function` which could be sigmoid, tanh, ReLu, etc.\n",
        "\n",
        "- a `preprocess_function` which is applied in each layer after calculating `Wx+b` but before applying the activation function. It can be used to implement batch normalization.\n",
        "\n",
        "Initially we set all these functions to the identity function. In other words, the base model is a purely linear model without any activation functions, normalization or anything like that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdOBKw9G0YPO"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "def base_normalizer(x): return x\n",
        "def base_activation(x): return x\n",
        "def base_preprocess(x): return x\n",
        "\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 normalizer = base_normalizer,\n",
        "                 activation_function = base_activation,\n",
        "                 preprocess_function = base_preprocess,\n",
        "                 L = 10,\n",
        "                 N = 16):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.W = nn.ParameterList() # List of weights\n",
        "        self.b = nn.ParameterList() # List of biases\n",
        "        self.L = L # Number of layers\n",
        "        self.N = N # Number of units in each hidden layer\n",
        "        self.activation_function = activation_function\n",
        "        self.preprocess_function = preprocess_function\n",
        "        self.layer_activations = [] # Store layer activations here\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        for layer in range(L):\n",
        "          dims = [self.N, self.N] # Size of hidden layer\n",
        "          if layer == 0: dims = [32*32*3,N] # Size of first layer\n",
        "          if layer == L-1: dims = [N,10] # Size of last layer\n",
        "          W = nn.Parameter(normalizer(torch.randn(dims[0], dims[1]))) # Call normalizer here\n",
        "          b = nn.Parameter(torch.zeros(dims[1]))\n",
        "          self.W.append(W)\n",
        "          self.b.append(b)\n",
        "\n",
        "    # Forward propagation\n",
        "    def forward(self, x):\n",
        "        self.layer_activations = []\n",
        "        x = x.view(-1, 32*32*3) # Vectorize image to a 32*32*3 dimensional vector\n",
        "        for layer in range(self.L):\n",
        "          x = x @ self.W[layer] + self.b[layer]\n",
        "          x = self.preprocess_function(x) # Call preprocess function before activation\n",
        "          x = self.activation_function(x)\n",
        "          self.layer_activations.append(x) # Store activations\n",
        "        return x\n",
        "\n",
        "    # Return stored layer activations\n",
        "    def activations(self):\n",
        "        return self.layer_activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83a4sLSObAyE"
      },
      "source": [
        "### 3.1 Test the model\n",
        "Let's test the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p68n0tD_bEFO"
      },
      "outputs": [],
      "source": [
        "# Move data to GPU\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "# Calculate scores\n",
        "model = BaseModel().to(device)\n",
        "scores = model(images)  # predictions\n",
        "\n",
        "print(scores.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP2f2yzibZXg",
        "tags": []
      },
      "source": [
        "### 3.2 Calculating the accuracy\n",
        "These numbers are scores (logits), which don't have any meaningful interpretation. We can convert them into class probabilities using softmax. Since we are only going to be interested in the model's accuracy, we will wrap the softmax inside the function `accuracy` that calculates the accuracy on a batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_hUiKnIcBZU"
      },
      "outputs": [],
      "source": [
        "def accuracy(scores, yb):\n",
        "    score2prob = nn.Softmax(dim=1)\n",
        "    preds = torch.argmax(score2prob(scores), dim=1)\n",
        "    return (preds == yb).float().mean()\n",
        "\n",
        "print('Accuracy', accuracy(scores,labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNpcQS3gzsZE"
      },
      "source": [
        "### Question\n",
        "1. What does `torch.argmax` do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gCGFOqycidx",
        "tags": []
      },
      "source": [
        "### 3.3 Calculating the loss\n",
        "I order to train your model, we also need a loss function. We will use the cross entropy loss [already provided in PyTorch](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.cross_entropy). Note that `cross_entropy` does the softmax for you, so the input is just the scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpdvLkhNxaTc"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "loss_func = F.cross_entropy\n",
        "loss = loss_func(scores, labels)\n",
        "print('Loss', loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SILeyqxcc7ed",
        "tags": []
      },
      "source": [
        "### 3.4 Getting layer activations and gradients\n",
        "One special ting about our model is that it stores the activations after each layer (in variable `self.layer_activations`).\n",
        "\n",
        "Our goal is develop tools that we can use to inspect our model both before and during training. For this purpose it will be useful to be able to grab the layer activations as well as the gradients at each layer. The activations have alreay been stored during our forward propagation and can be extracted as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diJkCQWMd3xH"
      },
      "outputs": [],
      "source": [
        "activations = model.activations()\n",
        "print('Activation list length:',len(activations))\n",
        "print('Activations shape layer 1:',activations[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojGryp4yeLDX"
      },
      "source": [
        "To get the gradients w.r.t. the loss, first call `loss.backward()` and then access the `grad` property of the relevant model parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7chAT_iNf9vf"
      },
      "outputs": [],
      "source": [
        "# Calculate gradients\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcypHRQ1gls5"
      },
      "source": [
        "*Side-note:* If you are interested in understanding in detail how `backward()` works, I recommend [this blog post](https://towardsdatascience.com/pytorch-autograd-understanding-the-heart-of-pytorchs-magic-2686cd94ec95).\n",
        "\n",
        "Since we are going to need both the layer activations and layer-wise gradients, lets wrap that up in a single function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btQ9Lid5glGN"
      },
      "outputs": [],
      "source": [
        "def get_layer_data(model):\n",
        "  gradients = []\n",
        "  layer_names = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for name, param in model.named_parameters():\n",
        "      if param.requires_grad and name.startswith('W'):\n",
        "          layer_names.append(name)\n",
        "          gradients.append(param.grad)\n",
        "\n",
        "  activations = model.activations()\n",
        "\n",
        "  return layer_names, activations, gradients\n",
        "\n",
        "layer_names, activations, gradients = get_layer_data(model)\n",
        "print('layer_names',layer_names)\n",
        "print('Activation list length:',len(activations))\n",
        "print('Activations shape layer 1:',activations[0].shape)\n",
        "print('Gradient list length:',len(gradients))\n",
        "print('Gradient shape layer 1:',gradients[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAz2dtpSiA3m"
      },
      "source": [
        "Note that we are not considering the biases in this Lab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VALKE9BohZIs"
      },
      "source": [
        "### Questions\n",
        "1. Why is the shape of the activations of the first layer [256,16]?\n",
        "2. Why is the shape of the gradients of the first layer [3072,16]?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaV8gN64ihO0"
      },
      "source": [
        "### 3.5 Getting layer stats\n",
        "We can create a simple function that calculates the mean and the variance of the layer activations and gradients. For the gradients, we are interested in the *gradient flow*, so we will take the mean of the absolute gradient values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IczlmBWRGkte"
      },
      "outputs": [],
      "source": [
        "def get_layer_stats(x,absolute=False):\n",
        "  avg = []\n",
        "  std = []\n",
        "  for layer in range(len(x)):\n",
        "    if absolute:\n",
        "      avg.append(x[layer].abs().mean().detach().cpu().numpy())\n",
        "    else:\n",
        "      avg.append(x[layer].mean().detach().cpu().numpy())\n",
        "\n",
        "    std.append(x[layer].std().detach().cpu().numpy())\n",
        "\n",
        "  return avg, std\n",
        "\n",
        "activation_mean, activation_std = get_layer_stats(activations)\n",
        "gradient_mean, gradient_std = get_layer_stats(gradients,absolute=True)\n",
        "\n",
        "print('activation_mean:\\n',activation_mean,'\\n')\n",
        "print('activation_std:\\n',activation_std,'\\n')\n",
        "print('gradient_mean:\\n',gradient_mean,'\\n')\n",
        "print('gradient_std:\\n',gradient_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiiKrxrGkH8w"
      },
      "source": [
        "### 3.6 Visualizing layer stats\n",
        "This is perhaps not very useful, so lets make a function that allows to plot histograms (and display mean and standard deviation at the same time).\n",
        "\n",
        "Note that you can specifiy a fixed range of x values (like -1 to 1). If set to `None` the x range is adapted to each individual plot. So notice the values on the x-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2il8nJOukZfk"
      },
      "outputs": [],
      "source": [
        "def plot_hist(hs,xrange=(-1,1),avg=None,sd=None):\n",
        "  plt.figure(figsize=(20,3))\n",
        "  for layer in range(len(hs)):\n",
        "    plt.subplot(1,len(hs),layer+1)\n",
        "    activations = hs[layer].detach().cpu().numpy().flatten()\n",
        "    plt.hist(activations, bins=20, range=xrange)\n",
        "\n",
        "    title = 'Layer ' + str(layer+1)\n",
        "    if avg:\n",
        "      title += '\\n' + \"mean {0:.2f}\".format(avg[layer])\n",
        "    if sd:\n",
        "      title += '\\n' + \"std {0:.4f}\".format(sd[layer])\n",
        "\n",
        "    plt.title(title)\n",
        "\n",
        "print('Gradients:\\n')\n",
        "plot_hist(gradients,xrange=None,avg=gradient_mean,sd=gradient_std)\n",
        "plt.show()\n",
        "\n",
        "print('Activations:\\n')\n",
        "plot_hist(activations,xrange=None,avg=activation_mean,sd=activation_std)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Infpb-u-l4Z2"
      },
      "source": [
        "### Questions\n",
        "Carefully inspect the histograms above, and remember that the x-axes can be scaled differently.\n",
        "1. What happens to the gradients across layers? How are they distributed? Do they get smaller or larger towards the end of the network?\n",
        "2. What about the activations?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9GH7xMKndnB",
        "tags": []
      },
      "source": [
        "### 3.7 Wrapping up\n",
        "Finally, let's combine all of the above into just one function that we can call. To do this we first define a helper function `get_stats` which takes a model as input, runs a batch trough the model, and calculates all the stats that we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IpKGmjVoJ_6"
      },
      "outputs": [],
      "source": [
        "def get_stats(model,dataloader=trainloader):\n",
        "\n",
        "  dataiter = iter(dataloader)\n",
        "  images, labels = dataiter.next()\n",
        "  images = images.to(device)\n",
        "  labels = labels.to(device)\n",
        "\n",
        "  scores = model(images)  # predictions\n",
        "  loss = loss_func(scores, labels)\n",
        "  acc = accuracy(scores,labels)\n",
        "\n",
        "  # Calculate gradients\n",
        "  loss.backward()\n",
        "\n",
        "  layer_names, activations, gradients = get_layer_data(model)\n",
        "\n",
        "  activation_mean, activation_std = get_layer_stats(activations)\n",
        "  gradient_mean, gradient_std = get_layer_stats(gradients,absolute=True)\n",
        "\n",
        "  stats = {'loss': loss,\n",
        "           'accuracy': acc,\n",
        "           'names': layer_names,\n",
        "           'grads': gradients,\n",
        "           'activations': activations,\n",
        "           'activation_mean': activation_mean,\n",
        "           'activation_std': activation_std,\n",
        "           'gradient_mean': gradient_mean,\n",
        "           'gradient_std': gradient_std\n",
        "           }\n",
        "\n",
        "  return stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBT8SJstoTpG"
      },
      "source": [
        "Here is the function to display the stats:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcy9gvEsx8bv"
      },
      "outputs": [],
      "source": [
        "def show_stats(stats):\n",
        "  print('loss',stats['loss'].detach().cpu().numpy())\n",
        "  print('accuracy',stats['accuracy'].detach().cpu().numpy(),'\\n')\n",
        "\n",
        "  print('Gradients:\\n')\n",
        "  print(' (note that we use the mean of the absolute gradient values to quantify gradient flow\\n')\n",
        "  #[print(name, avg, std) for name, avg, std in iter(zip(stats['names'],stats['gradient_mean'],stats['gradient_std']))]\n",
        "\n",
        "  plot_hist(stats['grads'],xrange=None,avg=stats['gradient_mean'],sd=stats['gradient_std'])\n",
        "  plt.show()\n",
        "\n",
        "  print('Activations:\\n')\n",
        "  #[print(name, avg, std) for name, avg, std in iter(zip(stats['names'],stats['activation_mean'],stats['activation_std']))]\n",
        "\n",
        "  plot_hist(stats['activations'],xrange=None,avg=stats['activation_mean'],sd=stats['activation_std'])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN8DoAeVoh5E"
      },
      "source": [
        "So from now on we just make these two function calls:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9YmjWw8Erer"
      },
      "outputs": [],
      "source": [
        "# Calculate stats\n",
        "stats = get_stats(model)\n",
        "\n",
        "# Show stats\n",
        "show_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zksMi4QUpZnP"
      },
      "source": [
        "## 4. Task 1: tanh activation\n",
        "Your task is very simple: Add tanh activation function to our base model and explain what you see. You can find inspiration [here](https://pytorch.org/docs/stable/generated/torch.tanh.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYTdu6g4wyQ-"
      },
      "outputs": [],
      "source": [
        "def tanh(x):\n",
        "  # Your code goes here\n",
        "  return\n",
        "\n",
        "model_tanh = BaseModel(activation_function=tanh).to(device)\n",
        "stats = get_stats(model_tanh)\n",
        "show_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRUIID0JqZ2t"
      },
      "source": [
        "### Questions:\n",
        "1. How are the gradients and activations distributed across layers?\n",
        "2. Is there gradient flow through the entire network?\n",
        "3. Do the activations have similar variance across layers?\n",
        "4. Are we within the linear range of tanh, within the saturated range, or a little of both?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_JhLhvprXIT"
      },
      "source": [
        "## 5. Task 2: Increase values of initial weights\n",
        "In our base model the weights are initialized with random values from a standard normal disitrbution (mean 0 and standard deviation 1). Let's increase the std to 10 and see what happens. Note that we keep using tanh acivation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5i3_DabFXbN"
      },
      "outputs": [],
      "source": [
        "def upscale(x): return x * 10\n",
        "\n",
        "model_saturated = BaseModel(normalizer=upscale, activation_function=tanh).to(device)\n",
        "stats = get_stats(model_saturated)\n",
        "show_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZcQmnrlr7WQ"
      },
      "source": [
        "### Questions:\n",
        "1. How are the gradients and activations distributed across layers?\n",
        "2. Is there gradient flow through the entire network?\n",
        "3. Do the activations have similar variance across layers?\n",
        "4. Are we within the linear range of tanh, within the saturated range, or a little of both?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3bOqMwBta9S",
        "tags": []
      },
      "source": [
        "## 6. Task 3: ReLu and Kaiming initialization\n",
        "Your task is to change the activation function to ReLU, which is faster than tanh and doesn't suffer from vanishing gradients.\n",
        "\n",
        "We will also use Kaiming weight initialization.\n",
        "You can check PyTorch's Kaiming formula [here](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_normal_) (again, recall that fan-in is the number of columns of the weight matrix).\n",
        "\n",
        "For ReLU you could use PyTorch's `F.relu` function. for kaiming, you could use `torch.nn.init.kaiming_normal_`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh4udDWJEXop",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model_kaiming = BaseModel(normalizer=YOUR_CODE_HERE, activation_function=YOUR_CODE_HERE).to(device)\n",
        "stats = get_stats(model_kaiming)\n",
        "show_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cExn9vfUuy_P"
      },
      "source": [
        "## 7. Task 4: Batch normalization\n",
        "Finally, see if you can implement simple batch normalization (without the learnable parameters) by passing on a preprocessing function to our model. The input to the preprocess function is the result of multiplying layer input `x` with weight matrix `W` and adding the biases: That is: `y = Wx+b`. The output should be `z = (y - mean(y)) / std(y)`. In real batch normalization, we train a scaling parameter, $\\gamma$, and a bias parameter, $\\beta$, but for now, we will leave out $\\gamma$ and $\\beta$.\n",
        "\n",
        "Hint: You can call `.mean()` and `.std()` on a tensor to get the mean and standard deviation, respectively. Remember to specify the correct dimensions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOkgJsggBdzd"
      },
      "outputs": [],
      "source": [
        "def batch_norm(y):\n",
        "  # Your code goes here\n",
        "  mu = y.mean(dim=0)\n",
        "  var = y.var(dim=0)\n",
        "  sigma = torch.sqrt(var + 1e-5)\n",
        "  z = (y - mu)/sigma\n",
        "  return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWQt9kr70psB"
      },
      "outputs": [],
      "source": [
        "# Check your results\n",
        "y = torch.randn(512,512)*10 + 2\n",
        "print('before', y.mean(),y.std())\n",
        "z = batch_norm(y)\n",
        "print('after', z.mean(),z.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNymTnEoDP-4"
      },
      "outputs": [],
      "source": [
        "model_batchnorm = BaseModel(normalizer=kaiming, activation_function=tanh,preprocess_function=batch_norm).to(device)\n",
        "stats = get_stats(model_batchnorm)\n",
        "show_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrsmRwouwO4a"
      },
      "source": [
        "### Questions:\n",
        "1. How are the gradients and activations distributed across layers?\n",
        "2. Is there gradient flow through the entire network?\n",
        "3. Do the activations have similar variance across layers?\n",
        "\n",
        "Try replacing the tanh activation with Relu\n",
        "\n",
        "4. Do enough of the ReLUs get activated in all layers?\n",
        "\n",
        "Compare to the results with ReLu and tanh (without batch norm).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "praCQ52q_LwQ"
      },
      "source": [
        "## 8. Model training\n",
        "The code below can be used to train a model and monitor important stats as training progresses.\n",
        "\n",
        "The training is carried out by calling the `fit` function, which takes a model as input, as well as a function handle returning an optimizer. The base optimizer is just SGD with zero momentum.\n",
        "\n",
        "In addition, `lr` is the learning rate, `bs` the batch size, and `epochs` the number of epochs.\n",
        "\n",
        "(Note: the cpu/gpu copying and torch/numpy conversions could have been made nicer - sorry...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56_hDxQWHKWo"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "\n",
        "# Function handle that returns an optimizer - in this case just a simple SGD without momentum\n",
        "def base_optimizer(model,lr=0.1):\n",
        "    return optim.SGD(model.parameters(), lr=lr,momentum=0.)\n",
        "\n",
        "# Used to print gradients/activations as a function of time\n",
        "def print_history(history,title=''):\n",
        "  plt.figure()\n",
        "  history = np.asarray(history)\n",
        "  lines = []\n",
        "  labels = []\n",
        "  for i in range(history.shape[1]):\n",
        "    l, = plt.plot(history[:,i])\n",
        "    lines.append(l)\n",
        "    labels.append('Layer ' + str(i+1))\n",
        "  plt.legend(lines, labels, loc=(1, 0), prop=dict(size=14))\n",
        "  plt.title(title)\n",
        "\n",
        "# Function to fit a model\n",
        "def fit(model,\n",
        "        opt_func=base_optimizer,\n",
        "        lr=0.1,\n",
        "        bs=256,\n",
        "        epochs=2):\n",
        "\n",
        "  train_dl = torch.utils.data.DataLoader(trainset, batch_size=bs,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "  valid_dl = torch.utils.data.DataLoader(testset, batch_size=bs,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "  opt = opt_func(model,lr) # Initialize optimizer\n",
        "\n",
        "  train_loss_history = []\n",
        "  valid_loss_history = []\n",
        "  plot_time_train = []\n",
        "  plot_time_valid = []\n",
        "  activation_mean_history = []\n",
        "  gradient_mean_history = []\n",
        "\n",
        "  t = 1\n",
        "\n",
        "  # Get initial validation loss and accuracy\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    valid_acc = sum(accuracy(model(xb.to(device)), yb.to(device)) for xb, yb in valid_dl) / len(valid_dl)\n",
        "    valid_loss = sum(loss_func(model(xb.to(device)), yb.to(device)) for xb, yb in valid_dl) / len(valid_dl)\n",
        "    valid_loss_history.append(valid_loss.detach().cpu().numpy())\n",
        "    plot_time_valid.append(t)\n",
        "\n",
        "  # Train\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for xb, yb in train_dl:\n",
        "      pred = model(xb.to(device))\n",
        "      loss = loss_func(pred, yb.to(device))\n",
        "\n",
        "      train_loss_history.append(loss.detach().cpu().numpy())\n",
        "      plot_time_train.append(t)\n",
        "      t += 1\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      layer_names, activations, gradients = get_layer_data(model)\n",
        "      activation_mean, activation_std = get_layer_stats(activations)\n",
        "      gradient_mean, gradient_std = get_layer_stats(gradients,absolute=True)\n",
        "      activation_mean_history.append(activation_mean)\n",
        "      gradient_mean_history.append(gradient_mean)\n",
        "\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "\n",
        "    # Validation loss and accuracy\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_acc = sum(accuracy(model(xb.to(device)), yb.to(device)) for xb, yb in valid_dl) / len(valid_dl)\n",
        "        valid_loss = sum(loss_func(model(xb.to(device)), yb.to(device)) for xb, yb in valid_dl) / len(valid_dl)\n",
        "        valid_loss_history.append(valid_loss.detach().cpu().numpy())\n",
        "        plot_time_valid.append(t-1)\n",
        "        if epoch == epochs-1:\n",
        "          print('validation loss',valid_loss.detach().cpu().numpy())\n",
        "          print('validation accuracy', valid_acc.detach().cpu().numpy())\n",
        "\n",
        "  # Summary\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(plot_time_train,train_loss_history)\n",
        "  plt.plot(plot_time_valid,valid_loss_history)\n",
        "\n",
        "  plt.title('Loss')\n",
        "\n",
        "  print_history(activation_mean_history,'Layer activations (mean)')\n",
        "  print_history(gradient_mean_history,'Layer gradients (mean)')\n",
        "\n",
        "  print('train loss',loss_func(model(xb.to(device)), yb.to(device)).detach().cpu().numpy())\n",
        "  print('train accuracy', accuracy(model(xb.to(device)), yb.to(device)).detach().cpu().numpy())\n",
        "  print('\\n')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V0LMYxaN85v",
        "tags": []
      },
      "source": [
        "### 8.1 Training the base model\n",
        "Let's train the base model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2Fi_LTo2QVp"
      },
      "outputs": [],
      "source": [
        "model = BaseModel().to(device) # Re-initialize weights\n",
        "fit(model,lr=1e-8)\n",
        "\n",
        "stats = get_stats(model)\n",
        "show_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV4VeuH12QVq"
      },
      "source": [
        "### Questions\n",
        "1. What is the validation accuracy?\n",
        "2. What do the first three plots show?\n",
        "3. What happened to the gradient flow over time? Did it increase, decrease, or stay constant?\n",
        "4. What happens if you increase the learning rate to 0.1?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufjD_62jPQSy"
      },
      "source": [
        "### 8.2 Training the tanh model\n",
        "Recall that the base model is entirely linear (i.e., no activation functions used). Let's see what happens if we add tanh activations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mk0H5D2LCT3t"
      },
      "outputs": [],
      "source": [
        "model_tanh = BaseModel(activation_function=tanh).to(device) # Re-initialize weights\n",
        "fit(model_tanh,lr=0.1)\n",
        "stats = get_stats(model_tanh)\n",
        "show_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkBQ4ZDMPhRv"
      },
      "source": [
        "### Questions\n",
        "1. Did results improve significantly?\n",
        "2. Are the activations within the linear range of tanh, within the saturated range, or a mix of both?\n",
        "3. What happens to the gradients over time?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPwnhZQhQNqd",
        "tags": []
      },
      "source": [
        "### 8.3 Could we possible do any worse?\n",
        "Yes! Let's use a std of 10 when initializing the weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPeBEzGEF2aN"
      },
      "outputs": [],
      "source": [
        "model_saturated = BaseModel(normalizer=upscale, activation_function=tanh).to(device) # Re-initialize weights\n",
        "fit(model_saturated,lr=0.1)\n",
        "stats = get_stats(model_saturated)\n",
        "show_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6ESARbbQjO6"
      },
      "source": [
        "### Questions\n",
        "1. What happens to the loss over time? Does it decrease?\n",
        "2. It seems that there is almost no gradient signal. Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU9vjEWr2QVy"
      },
      "source": [
        "### 8.4 Kaming initialization\n",
        "Now, let's see what happens with kaming initialization and ReLu:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3L7mg2YT2QVy"
      },
      "outputs": [],
      "source": [
        "kaiming = torch.nn.init.kaiming_normal_\n",
        "model_kaiming = BaseModel(normalizer=kaiming, activation_function=F.relu).to(device)\n",
        "fit(model_kaiming,lr=0.1)\n",
        "stats = get_stats(model_kaiming)\n",
        "show_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S-RHvPV2QVz"
      },
      "source": [
        "### Questions\n",
        "1. What happened to the validation accuracy?\n",
        "2. What happens to the gradient signal over time?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQJdvWcsSjZK"
      },
      "source": [
        "### 8.5 Batch normalization\n",
        "On average, results should become even better if we add batch normalization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ut46Hb6DrPW"
      },
      "outputs": [],
      "source": [
        "model_batchnorm = BaseModel(normalizer=kaiming, activation_function=F.relu,preprocess_function=batch_norm).to(device)\n",
        "fit(model_batchnorm,lr=0.1)\n",
        "stats = get_stats(model_batchnorm)\n",
        "show_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6Iiz96aS7iI"
      },
      "source": [
        "### Questions\n",
        "1. Compare the curves with and without from the model with batch normalization (i.e., section 8.4 and 8.5). Can you explain the differences?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NOgnYtEUXlL"
      },
      "source": [
        "## 9. Optimizers\n",
        "Below I have defined a few other optimizers (read more here: https://pytorch.org/docs/stable/optim.html). Your task is to experiment with these.\n",
        "\n",
        "Suggestions:\n",
        "\n",
        "1. Start with `momentum_optimizer` and train the model with momenum 0.0, 0.9, 0.99 and 1.0. Explain what happens.\n",
        "\n",
        "2. Move on to experiment with Adagrad or RMSprop. Notice any different behavior?\n",
        "\n",
        "3. Finally, try Adam with different learning rates. Theory says it shouldn't make a huge difference. Do your experiments confirm this?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46WEppfOLVQj"
      },
      "outputs": [],
      "source": [
        "#SGD + momentum\n",
        "def momentum_optimizer(model,lr=0.1):\n",
        "    return optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "def adagrad_optimizer(model,lr=0.1):\n",
        "  return optim.Adagrad(model.parameters(), lr=lr, lr_decay=0.0, weight_decay=0.0, initial_accumulator_value=0)\n",
        "\n",
        "def rmsprop_optimizer(model,lr=0.1):\n",
        "  return optim.RMSprop(model.parameters(), lr=lr, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
        "\n",
        "def adam_optimizer(model,lr=0.001):\n",
        "  return optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "\n",
        "model = BaseModel(normalizer=kaiming, activation_function=F.relu,preprocess_function=batch_norm).to(device)\n",
        "fit(model,opt_func=momentum_optimizer,lr=0.01,bs=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL_9mIyLB3_N"
      },
      "source": [
        "## 10. Competition\n",
        "How high validation accuracy can you get in 5 epochs?\n",
        "\n",
        "Rules - you are allowed to:\n",
        "- modify the number of layers of the base model (parameter `L`).\n",
        "- modify the unit in the hidden layers of the base model (parameter `N`).\n",
        "- choose between different activation functions and normalizers\n",
        "- use batch norm\n",
        "- change the batch size\n",
        "- use any optimizer and any optimization hyperparameters (e.g., learning rate)\n",
        "- and **no more than 5 epochs!**\n",
        "\n",
        "Think about your hyperparameter search strategy. What quick pre-experiments could you do before training the final model?\n",
        "\n",
        "Can you reach over 50% accuracy???"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZfIRcG0ZT62"
      },
      "outputs": [],
      "source": [
        "# Here is a baseline that you can compare with\n",
        "model = BaseModel(normalizer=kaiming, activation_function=F.relu,preprocess_function=batch_norm,L=3,N=128).to(device)\n",
        "fit(model,opt_func=adam_optimizer,lr=0.005,bs=256,epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPOCvs9eRdnb"
      },
      "source": [
        "## 11. Optional\n",
        "If you want a dataset, where you can achieve higher accuracy, try MNIST. Below are all the pieces you need to get started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi7Eh78p2QV5"
      },
      "outputs": [],
      "source": [
        "from mlxtend.data import mnist_data\n",
        "import random\n",
        "\n",
        "X, y = mnist_data()\n",
        "X = (X/255).astype(np.float32) # Convert to interval 0:1\n",
        "y = y.astype(np.float32)\n",
        "num_classes = 10\n",
        "nchannels, rows, cols = 1, 28, 28\n",
        "\n",
        "X = np.expand_dims(X.reshape(len(X),rows,cols),1) # Add a channel-dimension\n",
        "\n",
        "\n",
        "def splitdata(X, y, Ngroups, weights=None):\n",
        "    '''\n",
        "    X, y = input data and labels\n",
        "    Ngroups = number of groups to split data into\n",
        "    weights = a list with Ngroups weights, that tell the probability of a sample ending in either of the data sets\n",
        "    '''\n",
        "    if weights is None:\n",
        "        weights = [1/Ngroups]*Ngroups\n",
        "\n",
        "    groups = np.array(random.choices(list(range(Ngroups)), weights=weights, cum_weights=None, k=len(X)))\n",
        "    return ((X[np.where(groups==g)], y[np.where(groups==g)]) for g in np.array(range(Ngroups)))\n",
        "\n",
        "(x_train, y_train), (x_valid, y_valid) = splitdata(X, y, Ngroups=2, weights=[0.9, 0.1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr6zwwYSZgDR"
      },
      "outputs": [],
      "source": [
        "train_ds = torch.utils.data.TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
        "\n",
        "valid_ds = torch.utils.data.TensorDataset(torch.from_numpy(x_valid), torch.from_numpy(y_valid))\n",
        "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=bs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnl8gRJqP8nl"
      },
      "source": [
        "## 12. Batch normalization with learnable parameters\n",
        "Just for fun :-)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTq7mdZIfs4O"
      },
      "outputs": [],
      "source": [
        "# Batch norm with learnable parameters gamma and beta\n",
        "def batch_norm(y,gamma,beta):\n",
        "  mu = y.mean(dim=0)\n",
        "  var = y.var(dim=0)\n",
        "  sigma = torch.sqrt(var + 1e-5)\n",
        "  z = gamma*(y - mu)/sigma + beta\n",
        "  return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPLwyge4ihr_"
      },
      "outputs": [],
      "source": [
        "# Batch norm without learnable parameters (they have\n",
        "# to be there as input parameters, but they are not used).\n",
        "def batch_norm_no_learn(y,gamma,beta):\n",
        "  mu = y.mean(dim=0)\n",
        "  var = y.var(dim=0)\n",
        "  sigma = torch.sqrt(var + 1e-5)\n",
        "  z = (y - mu)/sigma\n",
        "  return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yvYJMYgf9NC"
      },
      "outputs": [],
      "source": [
        "# Check results\n",
        "y = torch.randn(32*32*3,16)*10 + 2\n",
        "print('before', y.mean(),y.std())\n",
        "gamma = torch.ones(16)\n",
        "beta = torch.zeros(16)\n",
        "z = batch_norm(y,gamma,beta)\n",
        "print('after', z.mean(),z.std())\n",
        "z = batch_norm_no_learn(y,gamma,beta)\n",
        "print('after (no learn)', z.mean(),z.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Raw03hCyjXVc"
      },
      "source": [
        "### Model extension\n",
        "Small extension of the model to enable learning of the batch norm parameters, gamma and beta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmSMRRMFbw3i"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "def base_normalizer(x): return x\n",
        "def base_activation(x): return x\n",
        "\n",
        "# This is the modified base preprocessor that returns the identity.\n",
        "# Only difference compared to above is that I have added two extra input\n",
        "# parameters gamma and beta, which have to be here, but are not used\n",
        "def base_preprocess(x,gamma,beta): return x\n",
        "\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 normalizer = base_normalizer,\n",
        "                 activation_function = base_activation,\n",
        "                 preprocess_function = base_preprocess,\n",
        "                 L = 10,\n",
        "                 N = 16):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.W = nn.ParameterList() # List of weights\n",
        "        self.b = nn.ParameterList() # List of biases\n",
        "        self.beta = nn.ParameterList() # BatchNorm\n",
        "        self.gamma = nn.ParameterList() # BatchNorm\n",
        "        self.L = L # Number of layers\n",
        "        self.N = N # Number of units in each hidden layer\n",
        "        self.activation_function = activation_function\n",
        "        self.preprocess_function = preprocess_function\n",
        "        self.layer_activations = [] # Store layer activations here\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        for layer in range(L):\n",
        "          dims = [self.N, self.N] # Size of hidden layer\n",
        "          if layer == 0: dims = [32*32*3,N] # Size of first layer\n",
        "          if layer == L-1: dims = [N,10] # Size of last layer\n",
        "          W = nn.Parameter(normalizer(torch.randn(dims[0], dims[1]))) # Call normalizer here\n",
        "          b = nn.Parameter(torch.zeros(dims[1]))\n",
        "          beta = nn.Parameter(torch.zeros(dims[1])) # NEW\n",
        "          gamma = nn.Parameter(torch.ones(dims[1])) # NEW\n",
        "          self.W.append(W)\n",
        "          self.b.append(b)\n",
        "          self.beta.append(beta) # NEW\n",
        "          self.gamma.append(gamma) # NEW\n",
        "\n",
        "    # Forward propagation\n",
        "    def forward(self, x):\n",
        "        self.layer_activations = []\n",
        "        x = x.view(-1, 32*32*3) # Vectorize image to a 32*32*3 dimensional vector\n",
        "        for layer in range(self.L):\n",
        "          x = x @ self.W[layer] + self.b[layer]\n",
        "          x = self.preprocess_function(x,self.gamma[layer],self.beta[layer]) # MODIFIED\n",
        "          x = self.activation_function(x)\n",
        "          self.layer_activations.append(x) # Store activations\n",
        "        return x\n",
        "\n",
        "    # Return stored layer activations\n",
        "    def activations(self):\n",
        "        return self.layer_activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F36nDrNaguub"
      },
      "outputs": [],
      "source": [
        "# Move data to GPU\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "# Calculate scores\n",
        "model = BaseModel().to(device)\n",
        "scores = model(images)  # predictions\n",
        "\n",
        "print(scores.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZxbTHwIj_E0"
      },
      "source": [
        "### Test - tanh and without batch norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc27ZP88g0PR"
      },
      "outputs": [],
      "source": [
        "model_tanh = BaseModel(activation_function=tanh).to(device) # Re-initialize weights\n",
        "fit(model_tanh,lr=0.1)\n",
        "stats = get_stats(model_tanh)\n",
        "show_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vynu7CxykX31"
      },
      "source": [
        "### Test - tanh with batch norm (with learnable parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVKl83PRhFFH"
      },
      "outputs": [],
      "source": [
        "model_tanh = BaseModel(activation_function=tanh,preprocess_function=batch_norm).to(device) # Re-initialize weights\n",
        "fit(model_tanh,lr=0.1)\n",
        "stats = get_stats(model_tanh)\n",
        "show_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JOVQESHkpta"
      },
      "source": [
        "### Test - tanh with simple batch norm (without learnable parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "059P2o9piM5F"
      },
      "outputs": [],
      "source": [
        "model_tanh = BaseModel(activation_function=tanh,preprocess_function=batch_norm_no_learn).to(device) # Re-initialize weights\n",
        "fit(model_tanh,lr=0.1)\n",
        "stats = get_stats(model_tanh)\n",
        "show_stats(stats)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc-showtags": false,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07bf959eedb4418e8e75eb96ca0adcee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bed645e0dfd14175b2aadfddd9519417",
            "placeholder": "",
            "style": "IPY_MODEL_ada66bc9efb4401e8d329e126dd84e21",
            "value": " 170500096/? [00:20&lt;00:00, 49515970.10it/s]"
          },
          "model_module_version": "1.5.0"
        },
        "0e9a6800a5f84b469fed68ab1e95c666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          },
          "model_module_version": "1.5.0"
        },
        "1abd5c7a5fb3464eb1debec6dcf5f58d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "56812773f2c3494eb909cdb58617a291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "5cf168e569e04dccbfb3bd735c6e95af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56812773f2c3494eb909cdb58617a291",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e9a6800a5f84b469fed68ab1e95c666",
            "value": 1
          },
          "model_module_version": "1.5.0"
        },
        "9e8fe30affad41a2b43bf4e2b55e63cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cf168e569e04dccbfb3bd735c6e95af",
              "IPY_MODEL_07bf959eedb4418e8e75eb96ca0adcee"
            ],
            "layout": "IPY_MODEL_1abd5c7a5fb3464eb1debec6dcf5f58d"
          },
          "model_module_version": "1.5.0"
        },
        "ada66bc9efb4401e8d329e126dd84e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          },
          "model_module_version": "1.5.0"
        },
        "bed645e0dfd14175b2aadfddd9519417": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}