{"cells":[{"cell_type":"markdown","metadata":{"id":"dGQcPAM1_pG8"},"source":["## Credit\n","This notebook is based on a notebook by Frederik Hvilsh√∏j [[4]](#References), which was created as part of a talk he held Wednesday, December 19th 2018, in the ML Journal Club at the Engineering Department at Aarhus University. It is inspired the paper by Kingma and Welling [[1]](#References) and the tutorial by Doersch [[2]](#References).\n","\n","\n","---\n","\n","\n","\n","\n","# Variational Auto-encoders\n","\n","\n","## Agenda\n","1. Introduction\n","2. Auto-encoders\n","3. Variational Auto-encoders"]},{"cell_type":"markdown","metadata":{"id":"_bxR18Zt_pHA"},"source":["## Introduction\n","\n","Deep neural networks is a class of very powerful models. In a usual scenario, we wish to approximate some function $f: X \\in \\mathbb{R}^{n \\times d} \\rightarrow Y \\in \\mathbb{R}^n$, from some data set $D = \\{(x_1, y_1), \\dots, (x_n, y_n)\\}$, where $x \\in X$ and $y \\in Y$. Typically, we train these networks by minimizing a loss function using mini-batch gradient descent on some loss function $\\mathcal{L}(\\Theta) = \\frac{1}{n} \\sum_{i =1}^n e(NN_\\Theta(x_i), y_i)$. Here, $\\Theta$ is the parameters of the neural network (NN) and $e$ is some error funtion.\n","\n","Let's see a small example"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"3IfBA-FG_pHD","colab":{"base_uri":"https://localhost:8080/","height":944,"referenced_widgets":["7d46275e1b04460795b4a3db886ce3ed","5da9358d4c19437fb78e44ca72b0678a","72407aaeecbc438c89e6b17fa3b97a8a","20cb96a0530f47338f598c45a156fcd4","612702396d5b41ba97c879f48bdb9438","0c939b2ea3204e50b09c20cd863e1c36","e5977b7bcde5497582a127b27f0f769c","ab725a6141374149a27485a40a9547d9","5f2c4cc49a0142189651f16151ff2bc3","59e1fcabfe1d44878df4dcf7e292dd27","02c3b983147846c4810d5ff58716aab6","3f3d20640162483caed9b410024ab749","171fa600e3f8404ea261a13a650129ec","235815fe9e404b76abbeda13dabe53bd","8aec3e5ad51549e583ce51ef29bc69a3","88df56e5ff4745bf9d15c400a211f9b7","89b158c2a9ec4a9a8f27a2e87aa6a593","3b57588c39194cfba66fa9d147916599","123dc9bff64844758df904488e890adc","9cb586eb2d3f404a93abd2397dd3affc","7c9632a0d13b4de9ab0b409527421b82","144875f3ec9440b0ae41dabde300021d","86cf7e5d32ec4b2f85283e4f64c7567b","e4c9a5e7dc3149a4a3f269efeb29b322","d0da911329bb4fc9922e792e74f9542e","dfe466aaeb6d41d2ba3a0e15fcdd7f99","98e9c990b34f4c528e89d4b1045ffa75","d5595b7a9c6047efb3f988e9572285c5","9f11ed3c74c347e4bcedfa6391e2ff39","67b0c7d8931545dfb5302405319cb045","f2739d898a784e8fbdd8a6801c2adbd5","fc8a722556914f259be421572ad77611","37a52089f4684e54b5dcc17530464385","a0a2851b99eb42e4a8f88f406f4ae3a8","a650bd2c42e5404fa7bafc8190328585","dc4f865dd89e4bcdb187f878780cefce","2b4884d3b14a450e8e38ab59954067d4","330ef1d8fbea40b4b1c94eac85b962a3","206c768af7bc4660956e25152fe99026","7cbf4a76cbaf46498d03e1dc88ed2a84","320748d2d3604793ad527a8ada3b06f3","841c9dd1beea448ea1b7f1dd97252540","3f0fb031f021438787a4d676e92c649f","7d94e431ac7041dd864c0d017906c502"]},"executionInfo":{"status":"ok","timestamp":1666600356027,"user_tz":-120,"elapsed":139446,"user":{"displayName":"Nhan Nguyen","userId":"04182665224922790535"}},"outputId":"9b8733fc-082a-4fcc-ab39-8a993e703a7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/9912422 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d46275e1b04460795b4a3db886ce3ed"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/28881 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f3d20640162483caed9b410024ab749"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1648877 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86cf7e5d32ec4b2f85283e4f64c7567b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/4542 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0a2851b99eb42e4a8f88f406f4ae3a8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","\n","Test set: Average loss: 0.5157, Accuracy: 8774/10000 (88%)\n","\n","\n","Test set: Average loss: 0.3791, Accuracy: 8991/10000 (90%)\n","\n","\n","Test set: Average loss: 0.3308, Accuracy: 9095/10000 (91%)\n","\n","\n","Test set: Average loss: 0.3058, Accuracy: 9150/10000 (92%)\n","\n","\n","Test set: Average loss: 0.2848, Accuracy: 9220/10000 (92%)\n","\n","\n","Test set: Average loss: 0.2716, Accuracy: 9246/10000 (92%)\n","\n","\n","Test set: Average loss: 0.2590, Accuracy: 9283/10000 (93%)\n","\n","\n","Test set: Average loss: 0.2463, Accuracy: 9313/10000 (93%)\n","\n","\n","Test set: Average loss: 0.2372, Accuracy: 9338/10000 (93%)\n","\n","\n","Test set: Average loss: 0.2285, Accuracy: 9360/10000 (94%)\n","\n"]}],"source":["from matplotlib import pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","\n","%matplotlib inline\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(784, 1000)\n","        self.fc2 = nn.Linear(1000, 10)\n","        \n","    def forward(self, x):\n","        x = x.view(-1, 28**2)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)\n","\n","def train(model, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","def test(model, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n","            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","\n","\n","batch_size = 120\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('./data', train=True, download=True,\n","                   transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       #transforms.Normalize((0.1307,), (0.3081,)),\n","                       lambda x: x\n","                   ])),\n","    batch_size=batch_size, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       #transforms.Normalize((0.1307,), (0.3081,)),\n","                       #transforms.Normalize((0.1307,), (0.3081,)),\n","                       lambda x: x\n","                   ])),\n","    batch_size=batch_size, shuffle=True)\n","\n","model = Net()\n","optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.5)\n","\n","for epoch in range(1, 11):\n","    train(model, train_loader, optimizer, epoch)\n","    test(model, test_loader)"]},{"cell_type":"markdown","metadata":{"id":"AWjPxHFJ_pHJ"},"source":["The approach shown above is typically used for classification or regression. In general, these approaches are known as discriminative models. There are also other usecases where we can set up a similar formulation of a loss function $\\mathcal{L}$ but with the intention of generating data from some distribution $p(x)$, i.e., generative models. For this purpose, there are two main directions. Namely, Generative Adversarial Networks (GANs) and Variational Auto-encoders (VAEs). In this note, we will explore the latter.\n","\n","To understand VAEs, we first need to understand auto-encoders in general."]},{"cell_type":"markdown","metadata":{"id":"SfUnJV_B_pHK"},"source":["## Auto-encoders"]},{"cell_type":"markdown","metadata":{"id":"MhYDLipc_pHL"},"source":["An auto-encoder is a very simple way of encoding data into some lower \n","dimensional latent space. The idea is to change the error function to \n","measure how well the model reconstructs the input to the model. One \n","example could be:\n","\n","$$\n","e(NN(x), x) = (NN(x) - x)^2\n","$$\n","\n","Then we can learn an internal representation or _embedding_ of the data\n","in the network by introducing a bottleneck in the data. \n","\n","![Standard Auto-encoder](autoencoder.png)\n","\n","Let's try this out."]},{"cell_type":"markdown","metadata":{"id":"-NEKQLsJ_pHN"},"source":["**Your task:** Build an autoencoder with the following layers:\n","\n","Encoder and Decoder:\n","\n","| Layer type    | Input size     | Output size |\n","|---------------|--------------|------------|\n","| linear + relu | # of pixels      | 100    |\n","| linear        | 100      | bottleneck_size    |\n","| linear + relu | bottleneck_size      | 100    |\n","| linear        | 100      | # of pixels    |\n","\n","**Questions**\n","1. what layers belong to the encoder and what layers belong to the decoder?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kvgeqLJV_pHO"},"outputs":[],"source":["bottleneck_size = 2\n","\n","class AutoEncoder(nn.Module):\n","    def __init__(self):\n","        super(AutoEncoder, self).__init__()\n","        # YOUR CODE STARTS HERE\n","\n","        # YOUR CODE ENDS HERE\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28**2)\n","        x = self.encode(x)\n","        x = self.decode(x)\n","        return x\n","\n","    def encode(self, x):\n","        # YOUR CODE STARTS HERE\n","\n","        # YOUR CODE ENDS HERE\n","        return x\n","\n","    def decode(self, x):\n","        # YOUR CODE STARTS HERE\n","\n","        # YOUR CODE ENDS HERE\n","        return x     \n","\n","\n","def draw(model):\n","    img = model(X_test).detach().numpy()\n","    img = img.reshape((-1, 28, 28)).transpose((1, 0, 2)).reshape(-1, 10*28)\n","    #img = img * 0.3081 + 0.1307\n","    axs[1].imshow(img, cmap='gray')\n","    axs[1].set_title('reconstructed data')\n","    fig.canvas.draw()\n","\n","def train(m, train_loader, optimizer, epoch, plot=None):\n","    m.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        output = m(data)\n","        if batch_idx % 100 == 0:\n","            draw(m)\n","\n","        # MSE Loss!\n","        loss = F.mse_loss(output, data.view(-1, 28**2))\n","        loss.backward()\n","        optimizer.step()\n","    print(f\"{epoch}: {loss}\")\n","\n","ae = AutoEncoder()"]},{"cell_type":"markdown","metadata":{"id":"VE-4zsay_pHQ"},"source":["Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vejtBde5_pHT"},"outputs":[],"source":["optimizer = optim.SGD(ae.parameters(), lr=1e-2, momentum=0.9)\n","# optimizer = optim.Adam(ae.parameters(), lr=1e-2)\n","\n","# Prepare some plotting\n","sample = next(iter(test_loader))\n","X_test = sample[0][:10].view(-1, 28, 28)\n","upper  = X_test.detach().numpy().transpose(1, 0, 2).reshape(-1, 10*28)\n","\n","fig, axs = plt.subplots(2, 1, figsize=(8,3))\n","fig.show()\n","axs[0].imshow(upper, cmap='gray')\n","axs[0].set_title('real data')\n","\n","for epoch in range(1, 11):\n","    train(ae, train_loader, optimizer, epoch)"]},{"cell_type":"markdown","metadata":{"id":"lx0r_L5-_pHV"},"source":["Now we can compress images into a two dimensional space, where we can actually plot their position against each other. Let's do that."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qAS230HZ_pHW"},"outputs":[],"source":["# This import registers the 3D projection, but is otherwise unused.\n","sample   = next(iter(train_loader))\n","X_train  = sample[0].view(-1, 28, 28)\n","embed    = ae.encode(X_train).detach().numpy()\n","\n","print(sample[1])\n","\n","\n","fig = plt.figure()\n","ax = fig.add_subplot(111)\n","ax.scatter(embed[:,0], embed[:,1], c=sample[1], cmap='Paired')\n","\n","plt.savefig('Autoencoder.pdf')"]},{"cell_type":"markdown","metadata":{"id":"wVykm5au_pHX"},"source":["This is okay but there is no clear relation between the classes and the embeddings. Okay, there are some tendencies, but it is not easy to generate new data. We could try though. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w3qvCem1_pHY"},"outputs":[],"source":["samples = np.zeros((10, 2))\n","for i in range(10):\n","    sel = sample[1] == i\n","    mu  = np.mean(embed[sel], axis=0)\n","    var = np.var(embed[sel], axis=0)\n","    samples[i] = np.random.multivariate_normal(mu, np.diag(var))\n","\n","# samples = np.random.normal(mu, np.diag(std), (10, 3))\n","generated = ae.decode(torch.from_numpy(samples).float())\n","\n","fig, ax = plt.subplots(figsize=(8,1.5))\n","\n","img = generated.detach().numpy()\n","img = img.reshape((-1, 28, 28)).transpose((1, 0, 2)).reshape(-1, 10*28)\n","#img = img * 0.3081 + 0.1307\n","ax.imshow(img, cmap='gray')\n"]},{"cell_type":"markdown","metadata":{"id":"6oU-PUBy_pHZ"},"source":["## Variational Auto-encoders\n"]},{"cell_type":"markdown","metadata":{"id":"mjwhx1c7_pHa"},"source":["The motivation is now to find a way to make the embeddings more structured. Here, we refer to structure as a simple distribution, that can easily be sampled from."]},{"cell_type":"markdown","metadata":{"id":"ZZz12Sn7_pHp"},"source":["Up til now, we have considered auto-encoders consisting of two components.\n","\n","1. An encoder $P(z | x)$, that approximates some unknown prior distribution $P(z | X)$\n","2. A decoder $P(X | z)$, that approximately decodes the latent variables, $z$,  into the space of $X$.\n","\n","The idea of VAE is to infer $P(z)$ using $P(z|X)$. I.e., we want to make our latent variable likely under our data.\n","We do this by modeling the true distribution $P(z|X)$ using a simpler distribution that is easy to evaluate, e.g. Gaussian, and minimize the difference between those two distribution using KL divergence."]},{"cell_type":"markdown","metadata":{"id":"lOAbozu9_pHq"},"source":["**Your task**\n","\n","The loss function is composed of two terms:\n","1. *Reconstruction term* on the final layer. \n","    * This term helps making the encoding-decoding scheme as performant as possible. You could use mean-square error,\n","    \n","    $L_{recon} = \\left \\| x-\\hat x \\right \\|_2^2$\n","    \n","1. *Regularisation term*  on the latent layer.\n","    * Regularise the organisation of the latent space by making the distributions returned by the encoder close to a standard normal distribution.\n","    * Expressed as the Kulback-Leibler divergence between the returned distribution and a standard Gaussian"]},{"cell_type":"markdown","metadata":{"id":"DCEhZ0Eq_pHr"},"source":["### Using Neural Networks\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R87G_Agx_pHs"},"outputs":[],"source":["bottleneck_size = 2\n","\n","class VAE(nn.Module):\n","    def __init__(self):\n","        super(VAE, self).__init__()\n","        self.fc1 = nn.Linear(28**2, 400)\n","        self.fc21 = nn.Linear(400, bottleneck_size)\n","        self.fc22 = nn.Linear(400, bottleneck_size)\n","        self.fc3 = nn.Linear(bottleneck_size, 400)\n","        self.fc4 = nn.Linear(400, 28**2)\n","\n","    def encode(self, x):\n","        x  = x.view(-1, 28**2)\n","        h1 = F.relu(self.fc1(x))\n","        mu = self.fc21(h1)\n","        log_sigma = self.fc22(h1)\n","        return mu, log_sigma\n","\n","    def reparameterize(self, mu, log_sigma):\n","        std = torch.exp(0.5*log_sigma)\n","        eps = torch.randn_like(std)\n","        return eps.mul(std).add_(mu)\n","    \n","    def decode(self, z):\n","        h3 = F.relu(self.fc3(z))\n","        return torch.sigmoid(self.fc4(h3))\n","\n","    def forward(self, x):\n","        mu, log_sigma = self.encode(x.view(-1, 28**2))\n","        z = self.reparameterize(mu, log_sigma)\n","        return self.decode(z), mu, log_sigma\n","\n","\n","vae = VAE()\n","optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n","\n","\n","def loss_function(recon_x, x, mu, z_log_sigma):\n","    # Since the image is in the range [0:1] we can use Binary Cross Entropy as reconstruction loss\n","    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n","    \n","    \n","    # https://agustinus.kristia.de/techblog/2016/12/10/variational-autoencoder/\n","    # In practice, it‚Äôs better to model Œ£(X) as logŒ£(X), \n","    # as it is more numerically stable to take exponent compared to computing log. \n","    # Hence, our final KL divergence term is:\n","    \n","    # D_KL(Q(z|X) || P(z|X)); calculate in closed form as both dist. are Gaussian\n","    KLD = 0.5* torch.sum( z_log_sigma.exp() + mu.pow(2) - z_log_sigma   - 1)\n","    \n","    return BCE + KLD\n","\n","def draw(model):\n","    img = model(X_test)[0].detach().numpy()\n","    img = img.reshape((-1, 28, 28)).transpose((1, 0, 2)).reshape(-1, 10*28)\n","    #img = img * 0.3081 + 0.1307\n","\n","    axs[1].imshow(img, cmap='gray')\n","    fig.canvas.draw()\n","\n","\n","def train(epoch):\n","    vae.train()\n","    train_loss = 0\n","    for batch_idx, (data, _) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        recon_batch, mu, log_sigma = vae(data)\n","        \n","        if batch_idx % 100 == 0:\n","            draw(vae)\n","\n","        loss = loss_function(recon_batch, data, mu, log_sigma)\n","        loss.backward()\n","        train_loss += loss.item()\n","        optimizer.step()\n","    print(f\"{epoch}: {train_loss / len(train_loader.dataset)}\")\n","\n","\n","fig, axs = plt.subplots(2, 1, figsize=(8,3))\n","fig.show()\n","axs[0].imshow(upper, cmap='gray')\n","    \n","for epoch in range(1, 11):\n","    train(epoch)\n"]},{"cell_type":"markdown","metadata":{"id":"yX4sBrSW_pHu"},"source":["**Questions**\n","1. The encoder outputs two variables: [mu, log_sigma]. What do you think they represent?\n","1. What is the purpose of the reparameterization? You may find the answer in [Kristia's blog](https://agustinus.kristia.de/techblog/2016/12/10/variational-autoencoder/)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XicTorG9_pHu"},"outputs":[],"source":["# This import registers the 3D projection, but is otherwise unused.\n","from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n","\n","X_train  = sample[0].view(-1, 28, 28)\n","mu, log_sigma    = vae.encode(X_train)\n","mu = mu.detach().numpy()\n","# var = torch.exp(logvar)\n","\n","fig = plt.figure()\n","ax = fig.add_subplot(111)\n","ax.scatter(mu[:,0], mu[:,1], c=sample[1], cmap='Paired')\n","ax.legend()\n","print(sample[1].unique())\n","\n","plt.savefig('VAE.pdf')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0UNAxVK_pHv"},"outputs":[],"source":["y = sample[1].numpy()\n","mean_0  = mu[y == 0]\n","mean_3  = mu[y == 3]\n","mean_0  = np.array([0, 5]) # mean_0.(axis=0)\n","mean_3  = np.array([0, 10]) # mean_0.mean(axis=0)\n","mean_0  = np.array([0, -5]) # mean_0.(axis=0)\n","mean_3  = np.array([-2, 0]) # mean_0.mean(axis=0)\n","\n","\n","diff    = (mean_0 - mean_3) / 10\n","Zs      = np.zeros((11, 2))\n","Zs[0]   = mean_3\n","for i in range(1, 11):\n","    Zs[i] = Zs[i-1] + diff\n","\n","print(Zs)\n","\n","# samples = np.random.normal(mu, np.diag(std), (10, 3))\n","generated = vae.decode(torch.from_numpy(Zs).float())\n","\n","fig, ax = plt.subplots(1, 2, figsize=(8,5))\n","\n","for i in range(10):\n","    sel = y == i\n","    ax[0].scatter(mu[sel,0], mu[sel,1], label=f\"{i}\")\n","ax[0].legend()\n","ax[0].plot(Zs[:,0], Zs[:,1], 'b--', label=\"Dir. of variation\")\n","\n","img = generated.detach().numpy()\n","img = img.reshape((-1, 28, 28)).transpose((1, 0, 2)).reshape(-1, 11*28)\n","#img = img * 0.3081 + 0.1307\n","ax[1].imshow(img, cmap='gray')"]},{"cell_type":"markdown","metadata":{"id":"auc5jFOJ_pHw"},"source":["**Questions**\n","\n","1. What do you think of this latent representation? In terms of quality? In terms of smoothness? Compare to the same plot for the traditional autoencoder.\n","1. Which digits does the model faithfully reconstruct? Which digits does it have trouble reconstructing? Why?\n","1. What happens if you set the weight of the KL term to, say 5 (KLD *= 5), and re-train the model?\n","\n","Encoding, decoding and latent space interpolation\n","\n","your task is to:\n","1. Encode an image of a 7 and an image of a 9.\n","1. Decode the encodings (to generate reconstructed images)\n","1. Interpolate between the two digits in latent space. You can use the code above as inspiration\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JqYyvO9y_pHx"},"source":["# References\n","[[1]](https://arxiv.org/pdf/1312.6114.pdf) Kingma, D.P. and Welling, M., 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114.  \n","\n","[[2]](https://arxiv.org/pdf/1606.05908.pdf) Doersch, C., 2016. Tutorial on variational autoencoders. arXiv preprint arXiv:1606.05908.\n","\n","[[3]](https://arxiv.org/pdf/1606.05579.pdf) Higgins, I., Matthey, L., Glorot, X., Pal, A., Uria, B., Blundell, C., Mohamed, S. and Lerchner, A., 2016. Early visual concept learning with unsupervised deep learning. arXiv preprint arXiv:1606.05579.\n","\n","[[4]](https://github.com/fhvilshoj/variational-autoencoders/blob/master/VAEs.ipynb) Frederik Hvilsh√∏j's github page"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GvRUWAwm_pHy"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"7d46275e1b04460795b4a3db886ce3ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5da9358d4c19437fb78e44ca72b0678a","IPY_MODEL_72407aaeecbc438c89e6b17fa3b97a8a","IPY_MODEL_20cb96a0530f47338f598c45a156fcd4"],"layout":"IPY_MODEL_612702396d5b41ba97c879f48bdb9438"}},"5da9358d4c19437fb78e44ca72b0678a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c939b2ea3204e50b09c20cd863e1c36","placeholder":"‚Äã","style":"IPY_MODEL_e5977b7bcde5497582a127b27f0f769c","value":"100%"}},"72407aaeecbc438c89e6b17fa3b97a8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab725a6141374149a27485a40a9547d9","max":9912422,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f2c4cc49a0142189651f16151ff2bc3","value":9912422}},"20cb96a0530f47338f598c45a156fcd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59e1fcabfe1d44878df4dcf7e292dd27","placeholder":"‚Äã","style":"IPY_MODEL_02c3b983147846c4810d5ff58716aab6","value":" 9912422/9912422 [00:00&lt;00:00, 54994500.87it/s]"}},"612702396d5b41ba97c879f48bdb9438":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c939b2ea3204e50b09c20cd863e1c36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5977b7bcde5497582a127b27f0f769c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab725a6141374149a27485a40a9547d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f2c4cc49a0142189651f16151ff2bc3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"59e1fcabfe1d44878df4dcf7e292dd27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02c3b983147846c4810d5ff58716aab6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f3d20640162483caed9b410024ab749":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_171fa600e3f8404ea261a13a650129ec","IPY_MODEL_235815fe9e404b76abbeda13dabe53bd","IPY_MODEL_8aec3e5ad51549e583ce51ef29bc69a3"],"layout":"IPY_MODEL_88df56e5ff4745bf9d15c400a211f9b7"}},"171fa600e3f8404ea261a13a650129ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89b158c2a9ec4a9a8f27a2e87aa6a593","placeholder":"‚Äã","style":"IPY_MODEL_3b57588c39194cfba66fa9d147916599","value":"100%"}},"235815fe9e404b76abbeda13dabe53bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_123dc9bff64844758df904488e890adc","max":28881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9cb586eb2d3f404a93abd2397dd3affc","value":28881}},"8aec3e5ad51549e583ce51ef29bc69a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c9632a0d13b4de9ab0b409527421b82","placeholder":"‚Äã","style":"IPY_MODEL_144875f3ec9440b0ae41dabde300021d","value":" 28881/28881 [00:00&lt;00:00, 349048.95it/s]"}},"88df56e5ff4745bf9d15c400a211f9b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89b158c2a9ec4a9a8f27a2e87aa6a593":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b57588c39194cfba66fa9d147916599":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"123dc9bff64844758df904488e890adc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cb586eb2d3f404a93abd2397dd3affc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c9632a0d13b4de9ab0b409527421b82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"144875f3ec9440b0ae41dabde300021d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86cf7e5d32ec4b2f85283e4f64c7567b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4c9a5e7dc3149a4a3f269efeb29b322","IPY_MODEL_d0da911329bb4fc9922e792e74f9542e","IPY_MODEL_dfe466aaeb6d41d2ba3a0e15fcdd7f99"],"layout":"IPY_MODEL_98e9c990b34f4c528e89d4b1045ffa75"}},"e4c9a5e7dc3149a4a3f269efeb29b322":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5595b7a9c6047efb3f988e9572285c5","placeholder":"‚Äã","style":"IPY_MODEL_9f11ed3c74c347e4bcedfa6391e2ff39","value":"100%"}},"d0da911329bb4fc9922e792e74f9542e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67b0c7d8931545dfb5302405319cb045","max":1648877,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f2739d898a784e8fbdd8a6801c2adbd5","value":1648877}},"dfe466aaeb6d41d2ba3a0e15fcdd7f99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc8a722556914f259be421572ad77611","placeholder":"‚Äã","style":"IPY_MODEL_37a52089f4684e54b5dcc17530464385","value":" 1648877/1648877 [00:00&lt;00:00, 4585938.98it/s]"}},"98e9c990b34f4c528e89d4b1045ffa75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5595b7a9c6047efb3f988e9572285c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f11ed3c74c347e4bcedfa6391e2ff39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67b0c7d8931545dfb5302405319cb045":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2739d898a784e8fbdd8a6801c2adbd5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc8a722556914f259be421572ad77611":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37a52089f4684e54b5dcc17530464385":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0a2851b99eb42e4a8f88f406f4ae3a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a650bd2c42e5404fa7bafc8190328585","IPY_MODEL_dc4f865dd89e4bcdb187f878780cefce","IPY_MODEL_2b4884d3b14a450e8e38ab59954067d4"],"layout":"IPY_MODEL_330ef1d8fbea40b4b1c94eac85b962a3"}},"a650bd2c42e5404fa7bafc8190328585":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_206c768af7bc4660956e25152fe99026","placeholder":"‚Äã","style":"IPY_MODEL_7cbf4a76cbaf46498d03e1dc88ed2a84","value":"100%"}},"dc4f865dd89e4bcdb187f878780cefce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_320748d2d3604793ad527a8ada3b06f3","max":4542,"min":0,"orientation":"horizontal","style":"IPY_MODEL_841c9dd1beea448ea1b7f1dd97252540","value":4542}},"2b4884d3b14a450e8e38ab59954067d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f0fb031f021438787a4d676e92c649f","placeholder":"‚Äã","style":"IPY_MODEL_7d94e431ac7041dd864c0d017906c502","value":" 4542/4542 [00:00&lt;00:00, 67196.92it/s]"}},"330ef1d8fbea40b4b1c94eac85b962a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"206c768af7bc4660956e25152fe99026":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cbf4a76cbaf46498d03e1dc88ed2a84":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"320748d2d3604793ad527a8ada3b06f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"841c9dd1beea448ea1b7f1dd97252540":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3f0fb031f021438787a4d676e92c649f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d94e431ac7041dd864c0d017906c502":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}